This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: .idea/**
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.gitignore
deploy/sql/init.sql
docker-compose.yml
flowsvr/pom.xml
flowsvr/src/main/java/com/zdf/flowsvr/constant/ErrorStatusReturn.java
flowsvr/src/main/java/com/zdf/flowsvr/constant/Task.java
flowsvr/src/main/java/com/zdf/flowsvr/controller/AsyncTaskController.java
flowsvr/src/main/java/com/zdf/flowsvr/controller/TaskScheduleCfgController.java
flowsvr/src/main/java/com/zdf/flowsvr/dao/AsyncFlowTaskDao.java
flowsvr/src/main/java/com/zdf/flowsvr/dao/ScheduleConfigDao.java
flowsvr/src/main/java/com/zdf/flowsvr/dao/TSchedulePosDao.java
flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncFlowClientData.java
flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncFlowTask.java
flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncTaskRequest.java
flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncTaskReturn.java
flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncTaskSetRequest.java
flowsvr/src/main/java/com/zdf/flowsvr/data/ConfigReturn.java
flowsvr/src/main/java/com/zdf/flowsvr/data/ReturnStatus.java
flowsvr/src/main/java/com/zdf/flowsvr/data/ScheduleConfig.java
flowsvr/src/main/java/com/zdf/flowsvr/data/TaskByTaskIdReturn.java
flowsvr/src/main/java/com/zdf/flowsvr/data/TaskList.java
flowsvr/src/main/java/com/zdf/flowsvr/data/TaskResult.java
flowsvr/src/main/java/com/zdf/flowsvr/data/TSchedulePos.java
flowsvr/src/main/java/com/zdf/flowsvr/data/UserTaskListRequest.java
flowsvr/src/main/java/com/zdf/flowsvr/enums/ErrorStatus.java
flowsvr/src/main/java/com/zdf/flowsvr/enums/TaskStatus.java
flowsvr/src/main/java/com/zdf/flowsvr/FlowsvrApplication.java
flowsvr/src/main/java/com/zdf/flowsvr/service/AsyncTaskService.java
flowsvr/src/main/java/com/zdf/flowsvr/service/impl/AsyncTaskServiceImpl.java
flowsvr/src/main/java/com/zdf/flowsvr/service/impl/ScheduleConfigServiceImpl.java
flowsvr/src/main/java/com/zdf/flowsvr/service/impl/TSchedulePosServiceImpl.java
flowsvr/src/main/java/com/zdf/flowsvr/service/ScheduleConfigService.java
flowsvr/src/main/java/com/zdf/flowsvr/service/TSchedulePosService.java
flowsvr/src/main/java/com/zdf/flowsvr/util/SnowFlake.java
flowsvr/src/main/java/com/zdf/flowsvr/util/Utils.java
flowsvr/src/main/resources/application.yml
flowsvr/src/main/resources/mappers/asynctask.xml
flowsvr/src/main/resources/mappers/schedule_cfg.xml
flowsvr/src/main/resources/mappers/TSchedulePosMapper.xml
flowsvr/src/test/java/com/zdf/flowsvr/FlowsvrApplicationTests.java
pom.xml
README.md
worker/pom.xml
worker/src/main/java/com/zdf/worker/boot/AppLaunch.java
worker/src/main/java/com/zdf/worker/boot/Launch.java
worker/src/main/java/com/zdf/worker/Client/TaskCfgBuilder.java
worker/src/main/java/com/zdf/worker/Client/TaskFlower.java
worker/src/main/java/com/zdf/worker/Client/TaskFlowerImpl.java
worker/src/main/java/com/zdf/worker/constant/TaskConstant.java
worker/src/main/java/com/zdf/worker/constant/TaskUrl.java
worker/src/main/java/com/zdf/worker/constant/UserConfig.java
worker/src/main/java/com/zdf/worker/core/AnnType.java
worker/src/main/java/com/zdf/worker/core/ObserverFunction.java
worker/src/main/java/com/zdf/worker/core/ObserverManager.java
worker/src/main/java/com/zdf/worker/core/observers/TimeObserver.java
worker/src/main/java/com/zdf/worker/data/AsyncFlowClientData.java
worker/src/main/java/com/zdf/worker/data/AsyncFlowTask.java
worker/src/main/java/com/zdf/worker/data/AsyncTaskBase.java
worker/src/main/java/com/zdf/worker/data/AsyncTaskRequest.java
worker/src/main/java/com/zdf/worker/data/AsyncTaskReturn.java
worker/src/main/java/com/zdf/worker/data/AsyncTaskSetRequest.java
worker/src/main/java/com/zdf/worker/data/AsyncTaskSetStage.java
worker/src/main/java/com/zdf/worker/data/ConfigReturn.java
worker/src/main/java/com/zdf/worker/data/NftTaskContext.java
worker/src/main/java/com/zdf/worker/data/ReturnStatus.java
worker/src/main/java/com/zdf/worker/data/ScheduleConfig.java
worker/src/main/java/com/zdf/worker/data/ScheduleData.java
worker/src/main/java/com/zdf/worker/data/ScheduleLog.java
worker/src/main/java/com/zdf/worker/data/TaskByTaskIdReturn.java
worker/src/main/java/com/zdf/worker/data/TaskList.java
worker/src/main/java/com/zdf/worker/enums/ErrorStatus.java
worker/src/main/java/com/zdf/worker/enums/TaskStatus.java
worker/src/main/java/com/zdf/worker/http/FlowServer.java
worker/src/main/java/com/zdf/worker/http/FlowServerImpl.java
worker/src/main/java/com/zdf/worker/lock/LockParam.java
worker/src/main/java/com/zdf/worker/lock/RedisLock.java
worker/src/main/java/com/zdf/worker/task/AsyncExecutable.java
worker/src/main/java/com/zdf/worker/task/Lark.java
worker/src/main/java/com/zdf/worker/task/TaskBuilder.java
worker/src/main/java/com/zdf/worker/task/TaskRet.java
worker/src/main/java/com/zdf/worker/test/Test.java
worker/src/main/java/com/zdf/worker/WorkerApplication.java
worker/src/main/resources/application.properties
worker/src/test/java/com/zdf/worker/WorkerApplicationTests.java

================================================================
Files
================================================================

================
File: .gitignore
================
HELP.md
target/
!.mvn/wrapper/maven-wrapper.jar
!**/src/main/**/target/
!**/src/test/**/target/

### STS ###
.apt_generated
.classpath
.factorypath
.project
.settings
.springBeans
.sts4-cache

### IntelliJ IDEA ###
.idea
*.iws
*.iml
*.ipr

### NetBeans ###
/nbproject/private/
/nbbuild/
/dist/
/nbdist/
/.nb-gradle/
build/
!**/src/main/**/build/
!**/src/test/**/build/

### VS Code ###
.vscode/

================
File: deploy/sql/init.sql
================
use asyncflow;
CREATE TABLE `t_lark_task_1`
(
    `id`                 int(11)                                  NOT NULL AUTO_INCREMENT,
    `user_id`            varchar(256) COLLATE utf8mb4_unicode_ci  NOT NULL DEFAULT '',
    `task_id`            varchar(256) COLLATE utf8mb4_unicode_ci  NOT NULL DEFAULT '',
    `task_type`          varchar(128) COLLATE utf8mb4_unicode_ci  NOT NULL DEFAULT '',
    `task_stage`         varchar(128) COLLATE utf8mb4_unicode_ci  NOT NULL DEFAULT '',
    `status`             tinyint(3) unsigned                      NOT NULL DEFAULT '0',
    `priority`           int(11)                                  NOT NULL DEFAULT '0' COMMENT '优先级',
    `crt_retry_num`      int(11)                                  NOT NULL DEFAULT '0' COMMENT '已经重试几次了',
    `max_retry_num`      int(11)                                  NOT NULL DEFAULT '0' COMMENT '最大能重试几次',
    `max_retry_interval` int(11)                                  NOT NULL DEFAULT '0' COMMENT '最大重试间隔',
    `schedule_log`       varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',
    `task_context`       varchar(8192) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '任务上下文，用户自定义',
    `order_time`         bigint                                   NOT NULL DEFAULT '0' COMMENT '调度时间，越小调度越优先',
    `create_time`        bigint,
    `modify_time`        bigint,
    PRIMARY KEY (`id`),
    UNIQUE KEY `idx_task_id` (`task_id`),
    KEY `idx_user_id` (`user_id`),
    KEY `idx_status` (`status`),
    KEY `idx_tasktype_status_modify_time` (`status`, `order_time`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4
  COLLATE = utf8mb4_unicode_ci;


CREATE TABLE `t_schedule_cfg`
(
    `task_type`           varchar(128) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '任务类型',
    `schedule_limit`      int(11)                                          DEFAULT '0' COMMENT '一次拉取多少个任务',
    `schedule_interval`   int(11)                                 NOT NULL DEFAULT '10',
    `max_processing_time` int(11)                                          DEFAULT '0' COMMENT '处于执行中的最大时间',
    `max_retry_num`       int(11)                                          DEFAULT '0' COMMENT '最大重试次数',
    `retry_interval`      int(11)                                          DEFAULT NULL COMMENT '重试间隔',
    `create_time`         bigint,
    `modify_time`         bigint,
    PRIMARY KEY (`task_type`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4
  COLLATE = utf8mb4_unicode_ci;

insert into t_schedule_cfg(task_type, schedule_limit, schedule_interval, max_processing_time,
                           max_retry_num, retry_interval)
values ('Lark', 100, 10, 30, 3, 10);

CREATE TABLE `t_schedule_pos`
(
    `id`                 bigint(20)                                                    NOT NULL AUTO_INCREMENT,
    `task_type`          varchar(256) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '',
    `schedule_begin_pos` int(11)                                                       NOT NULL DEFAULT '0' COMMENT '调度开始于几号表',
    `schedule_end_pos`   int(11)                                                       NOT NULL DEFAULT '0' COMMENT '调度结束于几号表',
    `create_time`        bigint,
    `modify_time`        bigint,
    PRIMARY KEY (`id`),
    UNIQUE KEY `idx_task_type` (`task_type`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4
  COLLATE = utf8mb4_unicode_ci;

insert into t_schedule_pos(task_type, schedule_begin_pos,
                           schedule_end_pos)
values ('lark', 1, 1);

================
File: docker-compose.yml
================
version: "3.8"
services:
  mysql:
    image: mysql:8.0
    container_name: async-flow-db
    restart: on-failure
    command:
      - --default_authentication_plugin=mysql_native_password
    environment:
      - MYSQL_ROOT_PASSWORD=root@2023
      - MYSQL_DATABASE=asyncflow
    ports:
      - "3306:3306"
    volumes:
      - ./deploy/sql:/docker-entrypoint-initdb.d

================
File: flowsvr/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>com.zdf</groupId>
        <artifactId>asyncflow-java</artifactId>
        <version>0.0.1-SNAPSHOT</version>
        <relativePath>../pom.xml</relativePath>
    </parent>

    <artifactId>flowsvr</artifactId>
    <name>flowsvr</name>
    <description>flowsvr</description>

    <dependencies>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>8.0.17</version>
        </dependency>

        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>druid-spring-boot-starter</artifactId>
            <version>1.2.15</version>
        </dependency>

        <dependency>
            <groupId>org.mybatis.spring.boot</groupId>
            <artifactId>mybatis-spring-boot-starter</artifactId>
            <version>2.0.1</version>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.8.1</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                    <encoding>UTF-8</encoding>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <version>2.7.6</version>
                <configuration>
                    <mainClass>com.zdf.flowsvr.FlowsvrApplication</mainClass>
                </configuration>
                <executions>
                    <execution>
                        <id>repackage</id>
                        <goals>
                            <goal>repackage</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

</project>

================
File: flowsvr/src/main/java/com/zdf/flowsvr/constant/ErrorStatusReturn.java
================
package com.zdf.flowsvr.constant;

import com.zdf.flowsvr.data.ReturnStatus;
import com.zdf.flowsvr.enums.ErrorStatus;
import com.zdf.flowsvr.enums.TaskStatus;

/**
 * 错误任务状态
 */
public class ErrorStatusReturn {
    public static ReturnStatus SUCCESS = new ReturnStatus(ErrorStatus.SUCCESS);
    public static ReturnStatus ERR_INPUT_INVALID = new ReturnStatus(ErrorStatus.ERR_INPUT_INVALID);
    public static ReturnStatus ERR_SHOULD_BIND = new ReturnStatus(ErrorStatus.ERR_SHOULD_BIND);
    public static ReturnStatus ERR_JSON_MARSHAL = new ReturnStatus(ErrorStatus.ERR_JSON_MARSHAL);
    public static ReturnStatus ERR_GET_TASK_INFO = new ReturnStatus(ErrorStatus.ERR_GET_TASK_INFO);
    public static ReturnStatus ERR_GET_TASK_HANDLE_PROCESS = new ReturnStatus(ErrorStatus.ERR_GET_TASK_HANDLE_PROCESS);
    public static ReturnStatus ERR_CREATE_TASK = new ReturnStatus(ErrorStatus.ERR_CREATE_TASK);
    public static ReturnStatus ERR_GET_TASK_LIST_FROM_DB = new ReturnStatus(ErrorStatus.ERR_GET_TASK_LIST_FROM_DB);
    public static ReturnStatus ERR_GET_TASK_SET_POS_FROM_DB = new ReturnStatus(ErrorStatus.ERR_GET_TASK_SET_POS_FROM_DB);
    public static ReturnStatus ERR_INCREASE_CRT_RETRY_NUM = new ReturnStatus(ErrorStatus.ERR_INCREASE_CRT_RETRY_NUM);
    public static ReturnStatus ERR_SET_TASK = new ReturnStatus(ErrorStatus.ERR_SET_TASK);
    public static ReturnStatus ERR_GET_TASK_POS = new ReturnStatus(ErrorStatus.ERR_GET_TASK_POS);
    public static ReturnStatus ERR_GET_PROCESSING_COUNT = new ReturnStatus(ErrorStatus.ERR_GET_PROCESSING_COUNT);
    public static ReturnStatus ERR_SET_USER_PRIORITY = new ReturnStatus(ErrorStatus.ERR_SET_USER_PRIORITY);
    public static ReturnStatus ERR_GET_TASK_CFG_FROM_DB = new ReturnStatus(ErrorStatus.ERR_GET_TASK_CFG_FROM_DB);

    public static boolean IsValidStatus(int status) {
        for (TaskStatus taskStatus : TaskStatus.values()) {
            if (status == taskStatus.getStatus()) {
                return true;
            }
        }
        return false;
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/constant/Task.java
================
package com.zdf.flowsvr.constant;

public class Task {
    public static int MAX_TASK_LIST_LIMIT = 1000;
    public static int DEFAULT_TASK_LIST_LIMIT = 1000;
    public static int DEFAULT_SET_TASK_STATUS = 0;
    public static String DEFAULT_SET_TASK_STAGE_SCHEDULELOG_CONTEXT = "";


}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/controller/AsyncTaskController.java
================
package com.zdf.flowsvr.controller;

import com.zdf.flowsvr.constant.ErrorStatusReturn;
import com.zdf.flowsvr.data.AsyncTaskRequest;
import com.zdf.flowsvr.data.AsyncTaskSetRequest;
import com.zdf.flowsvr.data.ReturnStatus;
import com.zdf.flowsvr.service.AsyncTaskService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;

import static com.zdf.flowsvr.util.Utils.isStrNull;

@RestController
@RequestMapping("/task")
public class AsyncTaskController {
    @Autowired
    private AsyncTaskService asyncTaskService;

    Logger logger = LoggerFactory.getLogger(AsyncTaskController.class);

    @PostMapping("/create_task")
    public ReturnStatus createTask(@RequestBody AsyncTaskRequest asyncTaskGroup) {
        if (isStrNull(asyncTaskGroup.getTaskData().getTask_type())){
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return asyncTaskService.createTask(asyncTaskGroup);
    }

    @GetMapping("/get_task")
    public ReturnStatus getTask(@RequestParam("task_id") String task_id) {
        if (isStrNull(task_id)){
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return asyncTaskService.getTask(task_id);
    }

    @GetMapping("/task_list")
    public ReturnStatus getTaskList(@RequestParam("task_type") String taskType, @RequestParam("status") int status, @RequestParam("limit") int limit) {
        if (isStrNull(taskType) || !ErrorStatusReturn.IsValidStatus(status)) {
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return asyncTaskService.getTaskList(taskType, status, limit);
    }

    @GetMapping("/hold_task")
    public ReturnStatus holdTask(@RequestParam("task_type") String taskType, @RequestParam("status") int status, @RequestParam("limit") int limit) {
        if (isStrNull(taskType) || !ErrorStatusReturn.IsValidStatus(status)) {
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return asyncTaskService.holdTask(taskType, status, limit);
    }



    @PostMapping("/set_task")
    public ReturnStatus addTask(@RequestBody AsyncTaskSetRequest asyncTaskSetRequest) {
        if (isStrNull(asyncTaskSetRequest.getTask_id())) {
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return asyncTaskService.setTask(asyncTaskSetRequest);
    }

    @GetMapping("/user_task_list")
    public ReturnStatus getUserTaskList(@RequestParam("user_id") String user_id, @RequestParam("status_list") int statusList) {
        if (isStrNull(user_id)) {
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return asyncTaskService.getTaskByUserIdAndStatus(user_id, statusList);
    }



}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/controller/TaskScheduleCfgController.java
================
package com.zdf.flowsvr.controller;

import com.zdf.flowsvr.constant.ErrorStatusReturn;
import com.zdf.flowsvr.data.ReturnStatus;
import com.zdf.flowsvr.data.ScheduleConfig;
import com.zdf.flowsvr.service.ScheduleConfigService;
import com.zdf.flowsvr.util.Utils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/task_schedule_cfg")
public class TaskScheduleCfgController {
    Logger logger = LoggerFactory.getLogger(TaskScheduleCfgController.class);


    @Autowired
    private ScheduleConfigService scheduleConfigService;

    @GetMapping("list")
    public ReturnStatus getTaskTypeCfgList() {
        return scheduleConfigService.getTaskTypeCfgList();
    }

    @GetMapping("task_configuration")
    public ReturnStatus SetTaskCFG(@RequestBody ScheduleConfig scheduleConfig) {
        if (Utils.isStrNull(scheduleConfig.getTask_type())) {
            logger.error("input invalid");
            return ErrorStatusReturn.ERR_INPUT_INVALID;
        }
        return scheduleConfigService.save(scheduleConfig);
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/dao/AsyncFlowTaskDao.java
================
package com.zdf.flowsvr.dao;

import com.zdf.flowsvr.data.AsyncFlowTask;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;

import java.util.List;

@Mapper
public interface AsyncFlowTaskDao {
    /**
     * 创建任务
     *
     * @param asyncFlowTask
     * @param tableName
     */
    void create(@Param("tableName") String tableName, @Param("asyncFlowTask") AsyncFlowTask asyncFlowTask);

    /**
     * 新增或更新任务
     *
     * @param asyncFlowTask
     * @param tableName
     */
    void save(@Param("asyncFlowTask") AsyncFlowTask asyncFlowTask, @Param("tableName") String tableName);

    /**
     * 获得对应状态的对应任务列表
     *
     * @param taskType  任务类型
     * @param status    任务状态
     * @param limit     限制数目
     * @param tableName
     * @return
     */
    List<AsyncFlowTask> getTaskList(@Param("taskType") String taskType, @Param("status") int status,
                                    @Param("limit") int limit, @Param("tableName") String tableName);

    /**
     * 更新任务信息
     *
     * @param asyncFlowTask
     * @param statuss
     * @param tableName
     */
    void updateTask(@Param("asyncFlowTask") AsyncFlowTask asyncFlowTask,
                    @Param("statuss") List<Integer> statuss, @Param("tableName") String tableName);

    /**
     * 获得活跃状态的任务
     *
     * @param statusList 活跃状态列表
     * @param tableName
     * @return
     */
    List<AsyncFlowTask> getAliveTaskList(@Param("statusList") List<Integer> statusList,
                                         @Param("tableName") String tableName);

    /**
     * 获取对应状态的任务数
     *
     * @param status 任务状态
     *               ≈
     * @return
     */
    int getTaskCountByStatus(@Param("status") int status, @Param("tableName") String tableName);

    /**
     * 获取任务状态列表中的任务数
     *
     * @param statusList
     * @param tableName
     * @return
     */
    int getTaskCount(@Param("statusList") List<Integer> statusList, @Param("tableName") String tableName);

    /**
     * 获取处于执行状态的超过最大执行时间的任务列表
     *
     * @param status         任务状态
     * @param limit          限制数目
     * @param maxProcessTime 任务最大执行时间
     * @param currentTime    当前时间
     * @param tableName
     * @return
     */
    List<AsyncFlowTask> getLongTimeProcessing(@Param("status") int status, @Param("limit") int limit,
                                              @Param("maxProcessTime") long maxProcessTime,
                                              @Param("currentTime") long currentTime,
                                              @Param("tableName") String tableName);

    /**
     * 增加重试次数
     *
     * @param taskId
     * @param tableName
     */
    void increaseCrtRetryNum(@Param("taskId") String taskId, @Param("tableName") String tableName);

    /**
     * 根据任务查找任务
     *
     * @param task_id
     * @param tableName
     * @return
     */
    AsyncFlowTask find(@Param("task_id") String task_id, @Param("tableName") String tableName);

    /**
     * 设置任务状态
     *
     * @param task_id
     * @param tableName
     */
    void setStatus(@Param("task_id") String task_id, @Param("tableName") String tableName);

    /**
     * 更改任务上下文
     *
     * @param task_id
     * @param tableName
     */
    void updateTask_contextByTask_id(@Param("task_id") String task_id, @Param("tableName") String tableName);

    /**
     * 更改超时的任务为Pending状态
     *
     * @param currentTime
     * @param maxProcessingTime
     * @param oldStatus
     * @param newStatus
     * @param tableName
     */
    void modifyTimeoutPending(@Param("currentTime") Long currentTime, @Param("maxProcessingTime") Long maxProcessingTime,
                              @Param("oldStatus") int oldStatus,
                              @Param("newStatus") int newStatus, @Param("tableName") String tableName);

    /**
     * 查看指定用户的任务
     *
     * @param user_id
     * @param statusList
     * @param tableName
     * @return
     */
    List<AsyncFlowTask> getTaskByUser_idAndStatus(@Param("user_id") String user_id, @Param("statusList") List<Integer> statusList,
                                                  @Param("tableName") String tableName);

    /**
     * 将列表中的任务修改为指定状态
     *
     * @param ids
     * @param status
     * @param tableName
     * @return
     */
    int updateStatusBatch(@Param("ids") List<String> ids, @Param("status") int status,
                          @Param("modifyTime") long modifyTime, @Param("tableName") String tableName);
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/dao/ScheduleConfigDao.java
================
package com.zdf.flowsvr.dao;

import com.zdf.flowsvr.data.ScheduleConfig;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;

import java.util.List;

@Mapper
public interface ScheduleConfigDao {
    /**
     * 根据任务类型获取任务配置
     *
     * @param task_type
     * @return
     */
    ScheduleConfig getTaskTypeCfg(@Param("task_type") String task_type);

    /**
     * 新增
     *
     * @param scheduleConfig
     */
    void save(@Param("scheduleConfig") ScheduleConfig scheduleConfig);

    /**
     * 获取所有任务配置列表
     *
     * @return
     */
    List<ScheduleConfig> getTaskTypeCfgList();

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/dao/TSchedulePosDao.java
================
package com.zdf.flowsvr.dao;

import com.zdf.flowsvr.data.TSchedulePos;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;

import java.util.List;

@Mapper
public interface TSchedulePosDao {

    /**
     * 新增或修改任务位置
     *
     * @param tSchedulePos
     */
    void save(@Param("tSchedulePos") TSchedulePos tSchedulePos);

    /**
     * 获取任务位置信息
     *
     * @param task_type
     * @return
     */
    TSchedulePos getTaskPos(@Param("task_type") String task_type);

    List<TSchedulePos> getTaskPosList();
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncFlowClientData.java
================
package com.zdf.flowsvr.data;

import lombok.Data;

@Data
public class AsyncFlowClientData {

    private String user_id;

    private String task_type;
    
    private String task_stage;

    private String schedule_log;

    private String task_context;

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncFlowTask.java
================
package com.zdf.flowsvr.data;


import lombok.Data;

@Data
public class AsyncFlowTask {
    
    private String id;
    
    private String user_id; //NOT NULL DEFAULT '',
    
    private String task_id; // NOT NULL DEFAULT '',
    
    private String task_type; //NOT NULL DEFAULT '',  存储任务的全类名
    
    private String task_stage; //NOT NULL DEFAULT '', 存储任务阶段信息
    
    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',
    
    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',
    
    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',

    private long order_time;

    private int priority;
    
    private int max_retry_interval;// int(11) NOT NULL DEFAULT '0' COMMENT '最大重试间隔',
    
    private String schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',
    
    private String task_context;// varchar(8192) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '任务上下文，用户自定义',
    
    private Long create_time;// datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    private Long modify_time;// datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncTaskRequest.java
================
package com.zdf.flowsvr.data;

import lombok.Data;

@Data
public class AsyncTaskRequest {
    AsyncFlowClientData taskData;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncTaskReturn.java
================
package com.zdf.flowsvr.data;

import lombok.AllArgsConstructor;
import lombok.Data;

@Data
@AllArgsConstructor
public class AsyncTaskReturn {
    private String user_id; //NOT NULL DEFAULT '',

    private String task_id; // NOT NULL DEFAULT '',

    private String task_type; //NOT NULL DEFAULT '',

    private String task_stage; //NOT NULL DEFAULT '',

    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',

    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',

    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',

    private int max_retry_interval;// int(11) NOT NULL DEFAULT '0' COMMENT '最大重试间隔',

    private String schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',

    private String task_context;

    private Long create_time;

    private Long modify_time;

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/AsyncTaskSetRequest.java
================
package com.zdf.flowsvr.data;

import lombok.Data;

@Data
public class AsyncTaskSetRequest {
    private String task_id; // NOT NULL DEFAULT '',

    private String task_stage;

    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',

    private String schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',

    private String task_context;

    private long order_time;

    private int priority;

    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',

    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',

    private int max_retry_interval;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/ConfigReturn.java
================
package com.zdf.flowsvr.data;

import lombok.AllArgsConstructor;
import lombok.Data;

import java.util.List;

@Data
@AllArgsConstructor
public class ConfigReturn {
    List<ScheduleConfig> scheduleCfgList;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/ReturnStatus.java
================
package com.zdf.flowsvr.data;

import com.zdf.flowsvr.enums.ErrorStatus;
import lombok.AllArgsConstructor;
import lombok.Data;

@Data
@AllArgsConstructor
public class ReturnStatus<E> {
    private String msg;
    private int code;
    private E result;

    public ReturnStatus() {

    }
    public ReturnStatus(ErrorStatus errorStatus) {
        this.code = errorStatus.getErrCode();
        this.msg = errorStatus.getMsg();
    }


    public ReturnStatus(E result) {
        this(ErrorStatus.SUCCESS);
        this.result = result;
    }

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/ScheduleConfig.java
================
package com.zdf.flowsvr.data;

import lombok.Data;

@Data
public class ScheduleConfig {
    private String task_type;
    private Integer schedule_limit;
    private Integer schedule_interval;
    private Integer max_processing_time;
    private Integer max_retry_num;
    private Integer retry_interval;
    private Long create_time;
    private Long modify_time;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/TaskByTaskIdReturn.java
================
package com.zdf.flowsvr.data;

import lombok.AllArgsConstructor;
import lombok.Data;

@Data
@AllArgsConstructor
public class TaskByTaskIdReturn<E> {
    E taskData;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/TaskList.java
================
package com.zdf.flowsvr.data;

import lombok.AllArgsConstructor;
import lombok.Data;

import java.util.List;

@Data
@AllArgsConstructor
public class TaskList {
    List<AsyncTaskReturn> taskList;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/TaskResult.java
================
package com.zdf.flowsvr.data;

import lombok.AllArgsConstructor;
import lombok.Data;

@Data
@AllArgsConstructor
public class TaskResult {
    private String task_id;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/TSchedulePos.java
================
package com.zdf.flowsvr.data;

import lombok.Data;

import java.io.Serializable;

/**
 * 
 * @TableName t_schedule_pos
 */
@Data
public class TSchedulePos implements Serializable {
    /**
     * 
     */
    private Long id;

    /**
     * 
     */
    private String taskType;

    /**
     * 调度开始于几号表
     */
    private Integer scheduleBeginPos;

    /**
     * 调度结束于几号表
     */
    private Integer scheduleEndPos;

    /**
     * 
     */
    private Long createTime;

    /**
     * 
     */
    private Long modifyTime;



}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/data/UserTaskListRequest.java
================
package com.zdf.flowsvr.data;

import lombok.Data;

import java.util.List;

@Data
public class UserTaskListRequest {
    String user_id;
    List<Integer> statusList;
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/enums/ErrorStatus.java
================
package com.zdf.flowsvr.enums;

/**
 * 错误状态和信息
 */
public enum ErrorStatus {
    SUCCESS(0, "ok"),
    ERR_INPUT_INVALID(8020, "input invalid"),
    ERR_SHOULD_BIND(8021, "should bind failed"),
    ERR_JSON_MARSHAL(8022, "json marshal failed"),
    ERR_GET_TASK_INFO(8035, "get task info failed"),
    ERR_GET_TASK_HANDLE_PROCESS(8036, "get task handle process Failed"),
    ERR_CREATE_TASK(8037, "create task failed"),
    ERR_GET_TASK_LIST_FROM_DB(8038, "get task list from db failed"),
    ERR_GET_TASK_SET_POS_FROM_DB(8039, "get task set pos from db failed"),
    ERR_INCREASE_CRT_RETRY_NUM(8040, "set task failed"),
    ERR_SET_TASK(8041, "increase crt retry num failed"),
    ERR_GET_TASK_POS(8042, "get task pos failed"),
    ERR_GET_PROCESSING_COUNT(8043, "get processing count failed"),
    ERR_SET_USER_PRIORITY(8045, "set user priority failed"),
    ERR_GET_TASK_CFG_FROM_DB(8046, "get task cfg failed"),
    ERR_SET_TASK_CFG_FROM_DB(8047, "set task cfg failed");

    private int errCode;
    private String msg;
    private ErrorStatus(int errCode, String msg) {
        this.errCode = errCode;
        this.msg = msg;
    }

    public int getErrCode() {
        return errCode;
    }

    public String getMsg() {
        return msg;
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/enums/TaskStatus.java
================
package com.zdf.flowsvr.enums;


/**
 * 任务状态
 */
public enum TaskStatus {
    PENDING(0x01),
    EXECUTING(0x02),
    SUCCESS(0x04),
    FAIL(0x08);

    private TaskStatus(int status) {
        this.status = status;
    }
    private int status;

    public int getStatus() {
        return this.status;
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/FlowsvrApplication.java
================
package com.zdf.flowsvr;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class FlowsvrApplication {

    public static void main(String[] args) {
        SpringApplication.run(FlowsvrApplication.class, args);
    }

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/service/AsyncTaskService.java
================
package com.zdf.flowsvr.service;


import com.zdf.flowsvr.data.AsyncTaskRequest;
import com.zdf.flowsvr.data.AsyncTaskSetRequest;
import com.zdf.flowsvr.data.ReturnStatus;

public interface AsyncTaskService {
    /**
     * 创建任务
     * @param asyncTaskRequest
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> createTask(AsyncTaskRequest asyncTaskRequest);

    /**
     * 获取任务列表
     * @param taskType
     * @param status
     * @param limit
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> getTaskList(String taskType, int status, int limit);

    /**
     * 更改任务信息
     * @param asyncTaskSetRequest
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> setTask(AsyncTaskSetRequest asyncTaskSetRequest);

    /**
     * 获取任务
     * @param task_id
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> getTask(String task_id);

    /**
     * 获取指定用户的任务列表
     * @param task_id
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> getTaskByUserIdAndStatus(String user_id, int statusList);


    /**
     * 占据任务
     * @param taskType
     * @param status
     * @param limit
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> holdTask(String taskType, int status, int limit);
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/service/impl/AsyncTaskServiceImpl.java
================
package com.zdf.flowsvr.service.impl;

import com.zdf.flowsvr.constant.ErrorStatusReturn;
import com.zdf.flowsvr.constant.Task;
import com.zdf.flowsvr.dao.AsyncFlowTaskDao;
import com.zdf.flowsvr.dao.ScheduleConfigDao;
import com.zdf.flowsvr.dao.TSchedulePosDao;
import com.zdf.flowsvr.data.*;
import com.zdf.flowsvr.enums.ErrorStatus;
import com.zdf.flowsvr.enums.TaskStatus;
import com.zdf.flowsvr.service.AsyncTaskService;
import com.zdf.flowsvr.util.Utils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;
import java.util.stream.Collectors;


/**
 * @author zhangdafeng
 */
@Service
public class AsyncTaskServiceImpl implements AsyncTaskService {
    Logger logger = LoggerFactory.getLogger(AsyncTaskServiceImpl.class);

    @Autowired
    private AsyncFlowTaskDao asyncFlowTaskDao;

    @Autowired
    private ScheduleConfigDao scheduleConfigDao;

    @Autowired
    private TSchedulePosDao tSchedulePosDao;


    private AsyncFlowClientData getAsyncFlowClientData(AsyncTaskRequest asyncTaskGroup) {
        AsyncFlowClientData asyncFlowClientData = asyncTaskGroup.getTaskData();
        return asyncFlowClientData;
    }

    @Override
    public <T> ReturnStatus<T> createTask(AsyncTaskRequest asyncTaskRequest) {
        AsyncFlowClientData asyncFlowClientData = getAsyncFlowClientData(asyncTaskRequest);
        TSchedulePos taskPos = null;
        try {
            taskPos = tSchedulePosDao.getTaskPos(asyncFlowClientData.getTask_type());
        } catch (Exception e) {
            return ErrorStatusReturn.ERR_GET_TASK_POS;
        }
        if (taskPos == null) {
            logger.error("db.TaskPosNsp.GetTaskPos failed.");
        }
        String tableName = getTableName(taskPos.getScheduleEndPos(), asyncFlowClientData.getTask_type());

        ScheduleConfig taskTypeCfg;
        try {
            taskTypeCfg = scheduleConfigDao.getTaskTypeCfg(asyncFlowClientData.getTask_type());
        } catch (Exception e) {
            logger.error("Visit t_task_type_cfg error");
            return ErrorStatusReturn.ERR_GET_TASK_SET_POS_FROM_DB;
        }

        AsyncFlowTask asyncFlowTask = new AsyncFlowTask();
        String taskId = getTaskId(asyncFlowClientData.getTask_type(), taskPos.getScheduleEndPos(), tableName);
        try {
            fillTaskModel(asyncFlowClientData, asyncFlowTask, taskId, taskTypeCfg);
            asyncFlowTaskDao.create(tableName, asyncFlowTask);
        } catch (Exception e) {
            e.printStackTrace();
            logger.error("create task error");
            return ErrorStatusReturn.ERR_CREATE_TASK;

        }
        TaskResult taskResult = new TaskResult(taskId);
        return new ReturnStatus(taskResult);
    }

    private String getTaskId(String taskType, int taskPos, String tableName) {
        return Utils.getTaskId() + "_" + taskType + "_" + tableName() + "_" + taskPos;
    }

    public void fillTaskModel (AsyncFlowClientData asyncFlowClientData, AsyncFlowTask asyncFlowTask, String taskId, ScheduleConfig taskTypeCfg) {
        asyncFlowTask.setTask_id(taskId);
        asyncFlowTask.setUser_id(asyncFlowClientData.getUser_id());
        asyncFlowTask.setTask_type(asyncFlowClientData.getTask_type());
        asyncFlowTask.setTask_stage(asyncFlowClientData.getTask_stage());
        Long currentTime = System.currentTimeMillis();
        asyncFlowTask.setModify_time(currentTime);
        asyncFlowTask.setMax_retry_interval(taskTypeCfg.getRetry_interval());
        asyncFlowTask.setMax_retry_num(taskTypeCfg.getMax_retry_num());
        asyncFlowTask.setCrt_retry_num(0);
        asyncFlowTask.setOrder_time(currentTime);
        asyncFlowTask.setCreate_time(currentTime);
        asyncFlowTask.setStatus(TaskStatus.PENDING.getStatus());
        asyncFlowTask.setSchedule_log(asyncFlowClientData.getSchedule_log());
        asyncFlowTask.setTask_context(asyncFlowClientData.getTask_context());
    }

    @Override
    public <T> ReturnStatus<T> holdTask(String taskType, int status, int limit) {
        if (limit > Task.MAX_TASK_LIST_LIMIT) {
            limit = Task.MAX_TASK_LIST_LIMIT;
        }
        if (limit == 0) {
            limit = Task.DEFAULT_TASK_LIST_LIMIT;
        }
        TSchedulePos taskPos;
        try {
            taskPos = tSchedulePosDao.getTaskPos(taskType);
        } catch (Exception e) {
            e.printStackTrace();
            return ErrorStatusReturn.ERR_GET_TASK_SET_POS_FROM_DB;
        }
        String tableName = getTableName(taskPos.getScheduleBeginPos(), taskType);
        List<AsyncFlowTask> taskList;
        try {
            taskList = asyncFlowTaskDao.getTaskList(taskType, status, limit, tableName);

        } catch (Exception e) {
            logger.error(ErrorStatus.ERR_GET_TASK_LIST_FROM_DB.getMsg());
            return ErrorStatusReturn.ERR_GET_TASK_LIST_FROM_DB;
        }
        List<AsyncFlowTask> filterList = taskList
                .stream()
                .parallel()
                .filter(asyncFlowTask -> asyncFlowTask.getCrt_retry_num() == 0 || asyncFlowTask.getMax_retry_interval() != 0
                        && asyncFlowTask.getOrder_time() <= System.currentTimeMillis()).collect(Collectors.toList());
        List<String> ids = conventTaskIdList(filterList);
        if (!ids.isEmpty()) {
            asyncFlowTaskDao.updateStatusBatch(ids, TaskStatus.EXECUTING.getStatus(), System.currentTimeMillis(), tableName);
        }
        List<AsyncTaskReturn> taskReturns = getTaskReturnList(filterList);
        TaskList list = new TaskList(taskReturns);
        return new ReturnStatus(list);
    }

    @Override
    public <T> ReturnStatus<T> getTaskList(String taskType, int status, int limit) {
        if (limit > Task.MAX_TASK_LIST_LIMIT) {
            limit = Task.MAX_TASK_LIST_LIMIT;
        }
        if (limit == 0) {
            limit = Task.DEFAULT_TASK_LIST_LIMIT;
        }
        TSchedulePos taskPos;
        try {
            taskPos = tSchedulePosDao.getTaskPos(taskType);
        } catch (Exception e) {
            e.printStackTrace();
            return ErrorStatusReturn.ERR_GET_TASK_SET_POS_FROM_DB;
        }
        String tableName = getTableName(taskPos.getScheduleBeginPos(), taskType);
        List<AsyncFlowTask> taskList;
        try {
             taskList = asyncFlowTaskDao.getTaskList(taskType, status, limit, tableName);

        } catch (Exception e) {
            logger.error(ErrorStatus.ERR_GET_TASK_LIST_FROM_DB.getMsg());
            return ErrorStatusReturn.ERR_GET_TASK_LIST_FROM_DB;
        }
        List<AsyncTaskReturn> taskReturns = getTaskReturns(taskList);
        TaskList list = new TaskList(taskReturns);
        return new ReturnStatus(list);
    }

    private List<AsyncTaskReturn> getTaskReturns(List<AsyncFlowTask> taskList) {
        List<AsyncTaskReturn> taskReturns = new ArrayList<>();
        for (AsyncFlowTask asyncFlowTask : taskList) {
            taskReturns.add(getTaskReturn(asyncFlowTask));
        }
        return taskReturns;
    }

    private AsyncTaskReturn getTaskReturn(AsyncFlowTask asyncFlowTask) {
        AsyncTaskReturn tr = new AsyncTaskReturn(
                asyncFlowTask.getUser_id(),
                asyncFlowTask.getTask_id(),
                asyncFlowTask.getTask_type(),
                asyncFlowTask.getTask_stage(),
                asyncFlowTask.getStatus(),
                asyncFlowTask.getCrt_retry_num(),
                asyncFlowTask.getMax_retry_num(),
                asyncFlowTask.getMax_retry_interval(),
                asyncFlowTask.getSchedule_log(),
                asyncFlowTask.getTask_context(),
                asyncFlowTask.getCreate_time(),
                asyncFlowTask.getModify_time()
        );
        return tr;


    }

    @Override
    public <T> ReturnStatus<T> setTask(AsyncTaskSetRequest asyncTaskSetRequest) {
        AsyncFlowTask asyncFlowTask;
        String tableName = getTableNameById(asyncTaskSetRequest.getTask_id());
        try {
            asyncFlowTask = asyncFlowTaskDao.find(asyncTaskSetRequest.getTask_id(), tableName);
        } catch (Exception e) {
            logger.error(ErrorStatus.ERR_GET_TASK_INFO.getMsg());
            return ErrorStatusReturn.ERR_GET_TASK_INFO;
        }

        if (asyncFlowTask == null) {
            logger.error("db.TaskPosNsp.Find Task failed. TaskId:%s", asyncTaskSetRequest.getTask_id());
            return ErrorStatusReturn.ERR_GET_TASK_INFO;
        }
        if (!isUnUpdate(asyncTaskSetRequest.getStatus())) {
            asyncFlowTask.setStatus(asyncTaskSetRequest.getStatus());
        }
        if (!isNullString(asyncTaskSetRequest.getTask_stage())) {
            asyncFlowTask.setTask_stage(asyncTaskSetRequest.getTask_stage());
        }
        if (!isNullString(asyncTaskSetRequest.getTask_context())) {
            asyncFlowTask.setTask_context(asyncTaskSetRequest.getTask_context());
        }
        if (!isNullString(asyncTaskSetRequest.getSchedule_log())) {
            asyncFlowTask.setSchedule_log(asyncTaskSetRequest.getSchedule_log());
        }
        if (!isUnUpdate(asyncTaskSetRequest.getCrt_retry_num())) {
            asyncFlowTask.setCrt_retry_num(asyncTaskSetRequest.getCrt_retry_num());
        }
        if (!isUnUpdate(asyncTaskSetRequest.getMax_retry_interval())) {
            asyncFlowTask.setMax_retry_interval(asyncTaskSetRequest.getMax_retry_interval());
        }
        if (!isUnUpdate(asyncTaskSetRequest.getMax_retry_num())) {
            asyncFlowTask.setMax_retry_num(asyncTaskSetRequest.getMax_retry_num());
        }
        if (asyncTaskSetRequest.getOrder_time() != 0) {
            asyncFlowTask.setOrder_time(asyncTaskSetRequest.getOrder_time());
        }
        if (!isUnUpdate(asyncTaskSetRequest.getPriority())) {
            asyncFlowTask.setPriority(asyncTaskSetRequest.getPriority());
        }

        asyncFlowTask.setModify_time(System.currentTimeMillis());
        try {
            List<Integer> list = new ArrayList<Integer>() {{
                add(TaskStatus.SUCCESS.getStatus());
                add(TaskStatus.FAIL.getStatus());
            }};
            asyncFlowTaskDao.updateTask(asyncFlowTask, list, tableName);
        } catch (Exception e) {
            e.printStackTrace();
            logger.error(ErrorStatus.ERR_SET_TASK.getMsg());
            return ErrorStatusReturn.ERR_SET_TASK;
        }
        return ErrorStatusReturn.SUCCESS;
    }

    private String getTableNameById(String taskId) {
        String[] strs = taskId.split("_");
        String tableName = getTableName(Integer.parseInt(strs[3]), strs[1]);
        return tableName;
    }

    private boolean isUnUpdate(int x) {
        return x == Task.DEFAULT_SET_TASK_STATUS;
    }

    private boolean isNullString(String s) {
        return s.equals(Task.DEFAULT_SET_TASK_STAGE_SCHEDULELOG_CONTEXT);
    }

    @Override
    public <T> ReturnStatus<T> getTask(String task_id) {
        AsyncFlowTask asyncFlowTask;
        String tableName = getTableNameById(task_id);
        try {
            asyncFlowTask = asyncFlowTaskDao.find(task_id, tableName);
        } catch (Exception e) {
            logger.error("get task info error");
            return ErrorStatusReturn.ERR_GET_TASK_INFO;
        }
        TaskByTaskIdReturn<AsyncTaskReturn> taskByTaskIdReturn = new TaskByTaskIdReturn(getTaskReturn(asyncFlowTask));
        return new ReturnStatus(taskByTaskIdReturn);
    }

    @Override
    public <T> ReturnStatus<T> getTaskByUserIdAndStatus(String user_id, int statusList) {

        List<AsyncFlowTask> asyncFlowTaskList;
        String tableName = getTableName(1, "LarkTask");
        try {
            asyncFlowTaskList = asyncFlowTaskDao.getTaskByUser_idAndStatus(user_id, getStatusList(statusList), tableName);
        } catch (Exception e) {
            logger.error("get task info error");
            return ErrorStatusReturn.ERR_GET_TASK_INFO;
        }
        List<AsyncTaskReturn> taskReturns = getTaskReturns(asyncFlowTaskList);
        TaskList list = new TaskList(taskReturns);
        return new ReturnStatus(list);
    }



    private List<Integer> getStatusList(int status) {
        List<Integer> statusList = new ArrayList<>();
        while (status != 0) {
            int cur = status & -status;
            statusList.add(cur);
            status ^= cur;
        }
        return statusList;
    }


    private List<AsyncTaskReturn> getAsyncTaskReturns(List<AsyncFlowTask> taskList) {
        return getTaskReturnList(taskList);
    }

    private List<AsyncTaskReturn> getTaskReturnList(List<AsyncFlowTask> taskList) {
        List<AsyncTaskReturn> tasks = new ArrayList<>();
        for (AsyncFlowTask asyncFlowTask : taskList) {
            AsyncTaskReturn asyncTaskReturn = new AsyncTaskReturn(
                    asyncFlowTask.getUser_id(),
                    asyncFlowTask.getTask_id(),
                    asyncFlowTask.getTask_type(),
                    asyncFlowTask.getTask_stage(),
                    asyncFlowTask.getStatus(),
                    asyncFlowTask.getCrt_retry_num(),
                    asyncFlowTask.getMax_retry_num(),
                    asyncFlowTask.getMax_retry_interval(),
                    asyncFlowTask.getSchedule_log(),
                    asyncFlowTask.getTask_context(),
                    asyncFlowTask.getCreate_time(),
                    asyncFlowTask.getModify_time()
            );
            tasks.add(asyncTaskReturn);
        }
        return tasks;
    }

    public List<String> conventTaskIdList(List<AsyncFlowTask> list) {
        return list.stream().map(AsyncFlowTask::getId).collect(Collectors.toList());
    }

    public int getTaskCountByStatus(TaskStatus taskStatus) {
        String tableName = getTableName(1, "LarkTask");
        return asyncFlowTaskDao.getTaskCountByStatus(taskStatus.getStatus(), tableName);
    }

    public int getAliveTaskCount() {
        String tableName = getTableName(1, "LarkTask");
        return asyncFlowTaskDao.getTaskCount(this.getAliveStatus(), tableName);
    }

    public int getAllTaskCount() {
        String tableName = getTableName(1, "LarkTask");
        return asyncFlowTaskDao.getTaskCount(this.getAllStatus(), tableName);
    }

    public List<AsyncFlowTask> getAliveTaskList() {
        String tableName = getTableName(1, "LarkTask");
        return asyncFlowTaskDao.getAliveTaskList(this.getAliveStatus(), tableName);
    }

    public List<Integer> getAliveStatus() {
        return new LinkedList<Integer>() {{
            add(TaskStatus.PENDING.getStatus());
            add(TaskStatus.EXECUTING.getStatus());
        }};
    }
    public List<Integer> getAllStatus() {
        return new LinkedList<Integer>() {{
            add(TaskStatus.PENDING.getStatus());
            add(TaskStatus.EXECUTING.getStatus());
            add(TaskStatus.SUCCESS.getStatus());
            add(TaskStatus.FAIL.getStatus());
        }};
    }

    public String getTableName(int pos, String taskType) {
        return "t_" + taskType.toLowerCase() + "_" + this.tableName() + "_" + pos;
    }

    public String tableName() {
        return "task";
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/service/impl/ScheduleConfigServiceImpl.java
================
package com.zdf.flowsvr.service.impl;

import com.zdf.flowsvr.constant.ErrorStatusReturn;
import com.zdf.flowsvr.dao.ScheduleConfigDao;
import com.zdf.flowsvr.data.ConfigReturn;
import com.zdf.flowsvr.data.ReturnStatus;
import com.zdf.flowsvr.data.ScheduleConfig;
import com.zdf.flowsvr.enums.ErrorStatus;
import com.zdf.flowsvr.service.ScheduleConfigService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;

@Service
public class ScheduleConfigServiceImpl implements ScheduleConfigService {
    @Autowired
    private ScheduleConfigDao scheduleConfigDao;

    Logger logger = LoggerFactory.getLogger(ScheduleConfigServiceImpl.class);

    @Override
    public <T> ReturnStatus<T> getTaskTypeCfgList() {
        List<ScheduleConfig> taskTypeCfgList;
        try {
            taskTypeCfgList = scheduleConfigDao.getTaskTypeCfgList();
        } catch (Exception e) {
            e.printStackTrace();
            logger.error(ErrorStatus.ERR_GET_TASK_CFG_FROM_DB.getMsg());
            return ErrorStatusReturn.ERR_GET_TASK_CFG_FROM_DB;
        }
        ConfigReturn configReturn = new ConfigReturn(taskTypeCfgList);
        return new ReturnStatus(configReturn);
    }

    @Override
    public <T> ReturnStatus<T> save(ScheduleConfig scheduleConfig) {
        long currentTimeMillis = System.currentTimeMillis();
        scheduleConfig.setCreate_time(currentTimeMillis);
        scheduleConfig.setModify_time(currentTimeMillis);
        try {
            scheduleConfigDao.save(scheduleConfig);
        } catch (Exception e) {
            e.printStackTrace();
            logger.error(ErrorStatus.ERR_SET_TASK_CFG_FROM_DB.getMsg());
        }
        return ErrorStatusReturn.SUCCESS;
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/service/impl/TSchedulePosServiceImpl.java
================
package com.zdf.flowsvr.service.impl;


import com.zdf.flowsvr.service.TSchedulePosService;
import org.springframework.stereotype.Service;

/**
* @author zhangdafeng
* @description 针对表【t_schedule_pos】的数据库操作Service实现
* @createDate 2023-01-14 12:22:04
*/
@Service
public class TSchedulePosServiceImpl implements TSchedulePosService{

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/service/ScheduleConfigService.java
================
package com.zdf.flowsvr.service;

import com.zdf.flowsvr.data.ReturnStatus;
import com.zdf.flowsvr.data.ScheduleConfig;

public interface ScheduleConfigService {
    /**
     * 获取任务列表
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> getTaskTypeCfgList();

    /**
     * 新增任务配置项
     * @param scheduleConfig
     * @param <T>
     * @return
     */
    <T> ReturnStatus<T> save(ScheduleConfig scheduleConfig);
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/service/TSchedulePosService.java
================
package com.zdf.flowsvr.service;

/**
* @author zhangdafeng
* @description 针对表【t_schedule_pos】
* @createDate 2023-01-14 12:22:04
*/
public interface TSchedulePosService {

}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/util/SnowFlake.java
================
package com.zdf.flowsvr.util;

/**
 * 雪花算法，用于生成任务ID
 */
class SnowFlake {


// ==============================Fields===========================================
    /**
     * 开始时间截 (2023-01-01)
     */
    private static final long twepoch = 1672502400000L;

    /**
     * 机器id所占的位数
     */
    private static final long workerIdBits = 5L;

    /**
     * 数据标识id所占的位数
     */
    private static final long datacenterIdBits = 5L;

    /**
     * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数)
     */
    private static final long maxWorkerId = ~(-1L << workerIdBits);

    /**
     * 支持的最大数据标识id，结果是31
     */
    private static final long maxDatacenterId = ~(-1L << datacenterIdBits);

    /**
     * 序列在id中占的位数
     */
    private static final long sequenceBits = 12L;

    /**
     * 机器ID向左移12位
     */
    private static final long workerIdShift = sequenceBits;

    /**
     * 数据标识id向左移17位(12+5)
     */
    private static final long datacenterIdShift = sequenceBits + workerIdBits;

    /**
     * 时间截向左移22位(5+5+12)
     */
    private static final long timestampLeftShift = sequenceBits + workerIdBits
            + datacenterIdBits;

    /**
     * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)
     */
    private static final long sequenceMask = ~(-1L << sequenceBits);

    /**
     * 工作机器ID(0~31)
     */
    private static long workerId;

    /**
     * 数据中心ID(0~31)
     */
    private static long datacenterId;

    /**
     * 毫秒内序列(0~4095)
     */
    private static long sequence = 0L;

    /**
     * 上次生成ID的时间截
     */
    private static long lastTimestamp = -1L;

// ==============================Constructors=====================================

    /**
     * 构造函数
     *
     * @param workerId     工作ID (0~31)
     * @param datacenterId 数据中心ID (0~31)
     */
    public SnowFlake(long workerId, long datacenterId) {
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format(
                    "worker Id can't be greater than %d or less than 0",
                    maxWorkerId));
        }
        if (datacenterId > maxDatacenterId || datacenterId < 0) {
            throw new IllegalArgumentException(String.format(
                    "datacenter Id can't be greater than %d or less than 0",
                    maxDatacenterId));
        }
        SnowFlake.workerId = workerId;
        SnowFlake.datacenterId = datacenterId;
    }

// ==============================Methods==========================================

    /**
     * 获得下一个ID (该方法是线程安全的)
     *
     * @return SnowflakeId
     */
    public static synchronized long nextId() {
        long timestamp = timeGen();

        // 如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常
        if (timestamp < lastTimestamp) {
            throw new RuntimeException(
                    String.format(
                            "Clock moved backwards.  Refusing to generate id for %d milliseconds",
                            lastTimestamp - timestamp));
        }

        // 如果是同一时间生成的，则进行毫秒内序列
        if (lastTimestamp == timestamp) {
            sequence = (sequence + 1) & sequenceMask;
            // 毫秒内序列溢出
            if (sequence == 0) {
                // 阻塞到下一个毫秒,获得新的时间戳
                timestamp = tilNextMillis(lastTimestamp);
            }
        }
        // 时间戳改变，毫秒内序列重置
        else {
            sequence = 0L;
        }

        // 上次生成ID的时间截
        lastTimestamp = timestamp;

        // 移位并通过或运算拼到一起组成64位的ID
        return ((timestamp - twepoch) << timestampLeftShift) //
                | (datacenterId << datacenterIdShift) //
                | (workerId << workerIdShift) //
                | sequence;
    }

    /**
     * 阻塞到下一个毫秒，直到获得新的时间戳
     *
     * @param lastTimestamp 上次生成ID的时间截
     * @return 当前时间戳
     */
    protected static long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }

    /**
     * 返回以毫秒为单位的当前时间
     *
     * @return 当前时间(毫秒)
     */
    protected static long timeGen() {
        return System.currentTimeMillis();
    }

    public SnowFlake() {
        this(0, 0);
    }

    // 生成id
    public static String getId() {
        return String.valueOf(SnowFlake.nextId());
    }

// ==============================Test=============================================

    /**
     * 测试
     */
    public static void main(String[] args) {
        System.out.println(SnowFlake.nextId());
    }
}

================
File: flowsvr/src/main/java/com/zdf/flowsvr/util/Utils.java
================
package com.zdf.flowsvr.util;


public class Utils {
    /**
     * 获得任务Id
     * @return
     */
    public static String getTaskId() {
        return SnowFlake.nextId() + "";
    }

    public static boolean isStrNull(String s) {
        return "".equals(s);
    }








}

================
File: flowsvr/src/main/resources/application.yml
================
server:
  port: 8081
  address: localhost

spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/asyncflow?serverTimezone=GMT%2B8&characterEncoding=utf8&useSSL=false
    username: root
    password: root@2023
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
        min-idle: 1                                          # 最小连接数
        max-active: 8                                         # 最大连接数(默认8)
        max-wait: 1000                                       # 获取连接时的最大等待时间
        min-evictable-idle-time-millis: 300000               # 一个连接在池中最小生存的时间，单位是毫秒
        time-between-eviction-runs-millis: 60000             # 多久才进行一次检测需要关闭的空闲连接，单位是毫秒

mybatis:
  mapper-locations: classpath:mappers/*.xml
  type-aliases-package: com.zdf.flowsvr.data
  #开启驼峰命名
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

================
File: flowsvr/src/main/resources/mappers/asynctask.xml
================
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<!--
namespace: 命名空间，用于标识每一个Mapper XML文件中的语句，预防在不同的Mapper XML文件中存在相同的语句ID
-->
<mapper namespace="com.zdf.flowsvr.dao.AsyncFlowTaskDao">
    <!--
        resultType: 也称为自动映射，只有在表的列名与POJO类的属性完全一致时使用，会比较方便，全类名
    -->

    <resultMap id="getTaskList" type="com.zdf.flowsvr.data.AsyncFlowTask">
        <result column="id" jdbcType="BIGINT" property="id" />
        <result column="user_id" jdbcType="VARCHAR" property="user_id"/>
        <result column="task_id" jdbcType="VARCHAR" property="task_id"/>
        <result column="task_type" jdbcType="VARCHAR" property="task_type"/>
        <result column="task_stage" jdbcType="VARCHAR" property="task_stage"/>
        <result column="status" jdbcType="INTEGER" property="status"/>
        <result column="crt_retry_num" jdbcType="INTEGER" property="crt_retry_num"/>
        <result column="max_retry_num" jdbcType="INTEGER" property="max_retry_num"/>
        <result column="priority" jdbcType="INTEGER" property="priority"/>
        <result column="order_time" jdbcType="BIGINT" property="order_time"/>
        <result column="max_retry_interval" jdbcType="INTEGER" property="max_retry_interval"/>
        <result column="schedule_log" jdbcType="VARCHAR" property="schedule_log"/>
        <result column="task_context" jdbcType="VARCHAR" property="task_context"/>
        <result column="create_time" jdbcType="BIGINT" property="create_time"/>
        <result column="modify_time" jdbcType="BIGINT" property="modify_time"/>
    </resultMap>
    <update id="increaseCrtRetryNum">
        update
            ${tableName}
        set
            crt_retry_num = crt_retry_num + 1
        where
            task_id = #{task_id}
    </update>
    <update id="updateTask"
            parameterType="com.zdf.flowsvr.data.AsyncFlowTask">
        update
        ${tableName}
        set
        user_id = #{asyncFlowTask.user_id},
        task_stage = #{asyncFlowTask.task_stage},
        status = #{asyncFlowTask.status},
        crt_retry_num = #{asyncFlowTask.crt_retry_num},
        max_retry_num = #{asyncFlowTask.max_retry_num},
        max_retry_interval = #{asyncFlowTask.max_retry_interval},
        schedule_log = #{asyncFlowTask.schedule_log},
        task_context = #{asyncFlowTask.task_context},
        create_time = #{asyncFlowTask.create_time},
        modify_time = #{asyncFlowTask.modify_time},
        order_time = #{asyncFlowTask.order_time}
        where
        task_id = #{asyncFlowTask.task_id}
        and
        status not in
        <foreach collection="statuss" item="s" index="index"
                 open="(" close=")" separator=",">
            #{s}
        </foreach>
    </update>
    <update id="setStatus">
        update
            ${tableName}
        set
            status = #{status}
        where
            task_id = #{task_id}
    </update>
    <update id="updateTask_contextByTask_id">
        update
            ${tableName}
        set
            task_context = #{task_context}
        where
            task_id = #{task_id}
    </update>
    <update id="modifyTimeoutPending">
        update
            ${tableName}
        set
            status = #{newStatus}
        where
            status = #{oldStatus}
          and
            modify_time + #{maxProcessingTime} &lt; #{currentTime};
    </update>
    <update id="updateStatusBatch">
        update ${tableName} set status = #{status}, modify_time = #{modifyTime}
        where id in
        <foreach collection="ids" item="s" index="index"
                 open="(" close=")" separator=",">
            #{s}
        </foreach>
    </update>

    <select id="getTaskList"
            resultMap="getTaskList">
        SELECT  *
        FROM ${tableName}
        where
            task_type = #{taskType} and status = #{status}
        order by order_time
        limit #{limit}
    </select>
    <select id="getAliveTaskList" resultType="com.zdf.flowsvr.data.AsyncFlowTask">
        select * from ${tableName}
        where
        status in
        <foreach collection="statusList" item="status" index="index"
                 open="(" close=")" separator=",">
            #{status}
        </foreach>
    </select>
    <select id="getTaskCountByStatus" resultType="java.lang.Integer"
            parameterType="java.lang.Integer">
        select count(*) from ${tableName}
        where
            status = #{status}
    </select>
    <select id="getLongTimeProcessing" resultType="com.zdf.flowsvr.data.AsyncFlowTask">
        select * from ${tableName}
        where
            status = #{status}
          and
            modify_time &lt; #{currentTime} - #{maxProcessTime}
    </select>
    <select id="find" resultMap="getTaskList">
        select * from ${tableName}
        where
            task_id = #{task_id}
    </select>
    <select id="getTaskCount" resultType="java.lang.Integer">
        select count(*) from ${tableName}
        where
        status in
        <foreach collection="statusList" item="status" index="index"
                 open="(" close=")" separator=",">
            #{status}
        </foreach>
    </select>
    <select id="getTaskByUser_idAndStatus" resultType="com.zdf.flowsvr.data.AsyncFlowTask">
        select * from ${tableName}
        where
        user_id = #{user_id}
        and
        status in
        <foreach collection="statusList" item="status" index="index"
                 open="(" close=")" separator=",">
            #{status}
        </foreach>
    </select>


    <insert id="create"
            useGeneratedKeys="true" keyProperty="asyncFlowTask.id">
        INSERT INTO ${tableName} (`user_id`,
                                  `task_id`,
                                  `task_type`,
                                  `task_stage`,
                                  `status`,
                                  `crt_retry_num`,
                                  `max_retry_num`,
                                  `order_time`,
                                  `priority`,
                                  `max_retry_interval`,
                                  `schedule_log`,
                                  `task_context`,
                                  `create_time`,
                                  `modify_time`)
        VALUES (#{asyncFlowTask.user_id},
                #{asyncFlowTask.task_id},
                #{asyncFlowTask.task_type},
                #{asyncFlowTask.task_stage},
                #{asyncFlowTask.status},
                #{asyncFlowTask.crt_retry_num},
                #{asyncFlowTask.max_retry_num},
                #{asyncFlowTask.order_time},
                #{asyncFlowTask.priority},
                #{asyncFlowTask.max_retry_interval},
                #{asyncFlowTask.schedule_log},
                #{asyncFlowTask.task_context},
                #{asyncFlowTask.create_time},
                #{asyncFlowTask.modify_time})
    </insert>
    <insert id="save" useGeneratedKeys="true" keyProperty="id">
        <selectKey keyProperty="count" resultType="int" order="BEFORE">
            select count(*) from ${tableName} where id = #{id}
        </selectKey>
        <if test="count > 0">
            update ${tableName}
            set
            user_id = #{asyncFlowTask.user_id},
            task_stage = #{asyncFlowTask.task_stage},
            status = #{asyncFlowTask.status},
            crt_retry_num = #{asyncFlowTask.crt_retry_num},
            max_retry_num = #{asyncFlowTask.max_retry_num},
            priority = {asyncFlowTask.priority},
            order_time = #{asyncFlowTask.order_time},
            max_retry_interval = #{asyncFlowTask.max_retry_interval},
            schedule_log = #{asyncFlowTask.schedule_log},
            task_context = #{asyncFlowTask.task_context},
            modify_time = #{asyncFlowTask.modify_time}
            where id = #{asyncFlowTask.id}
        </if>
        <if test="count==0">
            insert into ${tableName}
            VALUES (#{asyncFlowTask.user_id}, #{asyncFlowTask.task_id}, #{asyncFlowTask.task_type}, #{asyncFlowTask.task_stage},
            #{asyncFlowTask.status}, #{asyncFlowTask.crt_retry_num}, #{asyncFlowTask.priority}, #{asyncFlowTask.order_time},
            #{asyncFlowTask.max_retry_num}, #{asyncFlowTask.max_retry_interval},
            #{asyncFlowTask.schedule_log}, #{asyncFlowTask.task_context}, #{asyncFlowTask.create_time}, #{masyncFlowTask.odify_time})
        </if>

    </insert>

</mapper>

================
File: flowsvr/src/main/resources/mappers/schedule_cfg.xml
================
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<!--
namespace: 命名空间，用于标识每一个Mapper XML文件中的语句，预防在不同的Mapper XML文件中存在相同的语句ID
-->
<mapper namespace="com.zdf.flowsvr.dao.ScheduleConfigDao">
    <!--
        resultType: 也称为自动映射，只有在表的列名与POJO类的属性完全一致时使用，会比较方便，全类名
    -->
    <resultMap id="scheduleCFG" type="com.zdf.flowsvr.data.ScheduleConfig">
        <result column="task_type" jdbcType="VARCHAR" property="task_type"/>
        <result column="schedule_limit" jdbcType="INTEGER" property="schedule_limit"/>
        <result column="schedule_interval" jdbcType="INTEGER" property="schedule_interval"/>
        <result column="max_processing_time" jdbcType="INTEGER" property="max_processing_time"/>
        <result column="max_retry_num" jdbcType="INTEGER" property="max_retry_num"/>
        <result column="retry_interval" jdbcType="INTEGER" property="retry_interval"/>
        <result column="create_time" jdbcType="BIGINT" property="create_time"/>
        <result column="modify_time" jdbcType="BIGINT" property="modify_time"/>
    </resultMap>

    <select id="getTaskTypeCfg"
            resultMap="scheduleCFG"
            parameterType="java.lang.String">
        SELECT
               *
        FROM
             `t_schedule_cfg`
        where
            task_type = #{task_type}
    </select>
    <select id="getTaskTypeCfgList" resultMap="scheduleCFG">
        select * from t_schedule_cfg
    </select>
    <insert id="save"
            parameterType="com.zdf.flowsvr.data.ScheduleConfig">
        INSERT INTO `t_schedule_cfg`(`task_type`,
                                    `schedule_limit`,
                                    `schedule_interval`,
                                    `max_processing_time`,
                                    `max_retry_num`,
                                    `retry_interval`,
                                    `create_time`,
                                    `modify_time`)
        VALUES (#{task_type}, #{schedule_limit}, #{schedule_interval}, #{max_processing_time},
                #{max_retry_num}, #{retry_interval}, #{create_time}, #{modify_time})
    </insert>

</mapper>

================
File: flowsvr/src/main/resources/mappers/TSchedulePosMapper.xml
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper
        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.zdf.flowsvr.dao.TSchedulePosDao">

    <resultMap id="BaseResultMap" type="com.zdf.flowsvr.data.TSchedulePos">
            <id property="id" column="id" jdbcType="BIGINT"/>
            <result property="taskType" column="task_type" jdbcType="VARCHAR"/>
            <result property="dataBeginPos" column="data_begin_pos" jdbcType="INTEGER"/>
            <result property="dataEndPos" column="data_end_pos" jdbcType="INTEGER"/>
            <result property="scheduleBeginPos" column="schedule_begin_pos" jdbcType="INTEGER"/>
            <result property="scheduleEndPos" column="schedule_end_pos" jdbcType="INTEGER"/>
            <result property="createTime" column="create_time" jdbcType="BIGINT"/>
            <result property="modifyTime" column="modify_time" jdbcType="BIGINT"/>
    </resultMap>

    <insert id="save"
            parameterType="com.zdf.flowsvr.data.AsyncFlowTask"
            useGeneratedKeys="true" keyProperty="id">
        insert into t_schedule_pos (`task_type`,
                                    `data_begin_pos`,
                                    `data_end_pos`,
                                    `schedule_begin_pos`,
                                    `schedule_end_pos`,
                                    `create_time`,
                                    `modify_time`)
        VALUES (#{taskType}, #{dataBeginPos}, #{dataEndPos}, #{scheduleBeginPos},
                #{scheduleEndPos}, #{createTime}, #{modifyTime})
    </insert>
    <select id="getTaskPos" resultType="com.zdf.flowsvr.data.TSchedulePos">
        select * from t_schedule_pos
        where
            task_type = #{task_type}
    </select>
    <select id="getTaskPosList" resultType="com.zdf.flowsvr.data.TSchedulePos">
        select * from t_schedule_pos
    </select>


</mapper>

================
File: flowsvr/src/test/java/com/zdf/flowsvr/FlowsvrApplicationTests.java
================
package com.zdf.flowsvr;

import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;

@SpringBootTest
class FlowsvrApplicationTests {

    @Test
    void contextLoads() {
    }

}

================
File: pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>com.zdf</groupId>
    <artifactId>asyncflow-java</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <packaging>pom</packaging>
    <name>asyncflow-java</name>

    <description>asyncflow java version</description>

    <properties>
        <java.version>1.8</java.version>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <spring-boot.version>2.7.6</spring-boot.version>
        <lombok.version>1.18.22</lombok.version>
    </properties>

    <modules>
        <module>flowsvr</module>
        <module>worker</module>
    </modules>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
        </dependency>

        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <version>${lombok.version}</version>
            <scope>provided</scope>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>${spring-boot.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.8.1</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                    <encoding>UTF-8</encoding>
                </configuration>
            </plugin>
        </plugins>
    </build>

</project>

================
File: README.md
================
# asyncflow-java

## 初始化 mysql

```bash
#
# 初始化 mysql
docker compose up -d
# 检查 db 是否初始化成功
docker exec -it async-flow-db /usr/bin/mysql -uroot -proot@2023 -D asyncflow -e "show tables;"
```

## 启动 flowsvr

## 创建任务

## 启动 worker

================
File: worker/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>com.zdf</groupId>
        <artifactId>asyncflow-java</artifactId>
        <version>0.0.1-SNAPSHOT</version>
        <relativePath>../pom.xml</relativePath>
    </parent>

    <artifactId>worker</artifactId>
    <name>worker</name>
    <description>worker</description>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.squareup.okhttp3</groupId>
            <artifactId>okhttp</artifactId>
            <version>3.10.0</version>
        </dependency>
        <dependency>
            <groupId>com.alibaba</groupId>
            <artifactId>fastjson</artifactId>
            <version>1.2.28</version>
        </dependency>
        <dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>2.9.3</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.8.1</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                    <encoding>UTF-8</encoding>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <version>2.7.6</version>
                <configuration>
                    <mainClass>com.zdf.worker.WorkerApplication</mainClass>
                </configuration>
                <executions>
                    <execution>
                        <id>repackage</id>
                        <goals>
                            <goal>repackage</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

</project>

================
File: worker/src/main/java/com/zdf/worker/boot/AppLaunch.java
================
package com.zdf.worker.boot;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import com.zdf.worker.Client.TaskFlower;
import com.zdf.worker.Client.TaskFlowerImpl;
import com.zdf.worker.constant.TaskConstant;
import com.zdf.worker.constant.UserConfig;
import com.zdf.worker.core.ObserverManager;
import com.zdf.worker.core.observers.TimeObserver;
import com.zdf.worker.data.AsyncTaskBase;
import com.zdf.worker.data.AsyncTaskReturn;
import com.zdf.worker.data.AsyncTaskSetStage;
import com.zdf.worker.data.ScheduleConfig;
import com.zdf.worker.enums.TaskStatus;
import com.zdf.worker.task.Lark;
import com.zdf.worker.task.TaskBuilder;
import com.zdf.worker.task.TaskRet;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;

public class AppLaunch implements Launch{
    final TaskFlower taskFlower;//用于发送请求

    public static String packageName; //要执行的类的包名

    // 拉取哪几类任务
    static Class taskType;

    // 拉取哪个任务的指针
    AtomicInteger offset;

    // 观察者模式的观察管理者
    ObserverManager observerManager;
    private Long intervalTime;//请求间隔时间，读取用户配置
    private int scheduleLimit; //一次拉取多少个任务，用户配置
    public Long cycleScheduleConfigTime = 10000L;// 多长时间拉取一次任务配置信息
    public static int MaxConcurrentRunTimes = 5; // 线程池最大数量
    public static int concurrentRunTimes = MaxConcurrentRunTimes; // 线程并发数
    private static String LOCK_KEY = "lock"; // 分布式锁的键
    Map<String, ScheduleConfig> scheduleCfgDic; // 存储任务配置信息
    Logger logger = LoggerFactory.getLogger(AppLaunch.class); //打印日志
    ThreadPoolExecutor threadPoolExecutor; // 拉取任务的线程池
    ScheduledExecutorService loadPool;


    public AppLaunch() {
        this(0);
    }
    public AppLaunch(int scheduleLimit) {
        scheduleCfgDic = new ConcurrentHashMap<>();

        loadPool = Executors.newScheduledThreadPool(1);
        taskFlower = new TaskFlowerImpl();
        taskType = Lark.class;
        packageName = taskType.getPackage().getName();
        this.scheduleLimit = scheduleLimit;
        observerManager = new ObserverManager();
        // 向观察管理者注册观察者
        observerManager.registerEventObserver(new TimeObserver());
        offset = new AtomicInteger(0);
        // 初始化，拉取任务配置信息
        init();

    }

    // 启动：拉取任务
    @Override
    public int start() {
        // 读取对应任务配置信息
        ScheduleConfig scheduleConfig = scheduleCfgDic.get(taskType.getSimpleName());
        // 如果用户没有配置时间间隔就使用默认时间间隔
        intervalTime = scheduleConfig.getSchedule_interval() == 0 ? TaskConstant.DEFAULT_TIME_INTERVAL * 1000L : scheduleConfig.getSchedule_interval() * 1000L;
        this.threadPoolExecutor = new ThreadPoolExecutor(concurrentRunTimes, MaxConcurrentRunTimes, intervalTime + 1, TimeUnit.SECONDS, new LinkedBlockingQueue<>(UserConfig.QUEUE_SIZE));
        for(;;) {
            if (UserConfig.QUEUE_SIZE - threadPoolExecutor.getQueue().size() >= scheduleLimit) {
                execute(taskType);
            }
            try {
                Thread.sleep(intervalTime + (int)(Math.random() * 500));
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

        }
//        for (int i = 0; i < concurrentRunTimes; i++) {
//            // 前后波动500ms
//            int step = (int) (Math.random() * 500 + 1);
//            // 拉取任务
//            threadPoolExecutor.scheduleAtFixedRate(this::execute, step * 3L, intervalTime + step, TimeUnit.MILLISECONDS);
//        }
    }

    public void execute(Class<?> taskType) {
        List<AsyncTaskBase> asyncTaskBaseList = scheduleTask(taskType);
        if (asyncTaskBaseList == null) {
            return;
        }
        int size = asyncTaskBaseList.size();
        for (int i = 0; i < size; i++) {
            int finalI = i;
            threadPoolExecutor.execute(() -> executeTask(asyncTaskBaseList, finalI));
        }
    }

    // 拉取任务
    private List<AsyncTaskBase> scheduleTask(Class<?> taskType) {
        try {
            // 开始执行时，做点事，这里就是简单的打印了一句话，供后续扩展使用
            observerManager.wakeupObserver(ObserverType.onBoot);
        } catch (InvocationTargetException | IllegalAccessException e) {
            e.printStackTrace();
        }

        // 调用拉取任务接口拉取任务
        List<AsyncTaskBase> asyncTaskBaseList = getAsyncTaskBases(observerManager, taskType);
        // 为空判断
        if (asyncTaskBaseList == null || asyncTaskBaseList.size() == 0) {
            return null;
        }
        return asyncTaskBaseList;
    }

    // 执行任务
    private void executeTask(List<AsyncTaskBase> asyncTaskBaseList, int i) {
        AsyncTaskBase v = asyncTaskBaseList.get(i);
        try {
            // 执行前干点事，这里就打印了一句话，后续可以扩展
            observerManager.wakeupObserver(ObserverType.onExecute, v);
        } catch (InvocationTargetException | IllegalAccessException e) {
            e.printStackTrace();
        }
        AsyncTaskSetStage asyncTaskSetStage = null;
        Class<?> aClass = null;
        try {
            // 利用Java反射执行本地方法
            aClass = getaClass(v.getTask_type());
            Method method = TaskBuilder.getMethod(aClass, v.getTask_stage(), v.getTask_context().getParams(), v.getTask_context().getClazz());
            System.out.println(method.getName());
            TaskRet returnVal = (TaskRet) method.invoke(aClass.newInstance(), v.getTask_context().getParams());
            if (returnVal != null) {
                asyncTaskSetStage = returnVal.getAsyncTaskSetStage();
                Object result = returnVal.getResult();
                System.out.println("执行结果为：" + result);
            }
        } catch (Exception e) {
            try {
                // 执行出现异常了（任务执行失败了）更改任务状态为PENDING，重试次数+1，超过重试次数设置为FAIL
                observerManager.wakeupObserver(ObserverType.onError, v, scheduleCfgDic.get(v.getTask_type()), asyncTaskBaseList, aClass, e);
                return;
            } catch (InvocationTargetException | IllegalAccessException ex) {
                ex.printStackTrace();
            }
        }
        try {
            // 正常执行成功了干点事，方便后续扩展
            observerManager.wakeupObserver(ObserverType.onFinish, v, asyncTaskSetStage, aClass);
        } catch (InvocationTargetException | IllegalAccessException e) {
            e.printStackTrace();
        }
    }

    public Class<?> getaClass(String taskType) throws ClassNotFoundException {
        Class<?> aClass = Class.forName(packageName + "." + taskType);
        return aClass;
    }

    private List<AsyncTaskBase> getAsyncTaskBases(ObserverManager observerManager, Class<?> taskType) {
// 分布式锁的参数
        //        LockParam lockParam = new LockParam(LOCK_KEY);
        // 分布式锁
//        RedisLock redisLock = new RedisLock(lockParam);
        List<AsyncTaskReturn> taskList = null;
        try {
            // 上锁
         //   if (redisLock.lock()) {
            // 调用http请求接口
                taskList = taskFlower.getTaskList(taskType, TaskStatus.PENDING.getStatus(), scheduleCfgDic.get(taskType.getSimpleName()).getSchedule_limit());
                if (taskList == null || taskList.size() == 0) {
                    logger.warn("no task to deal!");
                    return null;
                }
                try {
                    List<AsyncTaskBase> asyncTaskBaseList = new ArrayList<>();
                    observerManager.wakeupObserver(ObserverType.onObtain, taskList, asyncTaskBaseList);
                    return asyncTaskBaseList;
                } catch (InvocationTargetException | IllegalAccessException e) {
                    e.printStackTrace();
                }
       //     }
        } catch (Exception e) {
            e.printStackTrace();
        }
//        finally {
        // 释放锁
//            redisLock.unlock();
//        }

        return null;
    }

    // 拉取任务配置信息
    private void loadCfg() {
        List<ScheduleConfig> taskTypeCfgList = taskFlower.getTaskTypeCfgList();
        for (ScheduleConfig scheduleConfig : taskTypeCfgList) {
            scheduleCfgDic.put(scheduleConfig.getTask_type(), scheduleConfig);
        }
    }

    @Override
    public int init() {
        loadCfg();
        if (scheduleLimit != 0) {
            logger.debug("init ScheduleLimit : %d", scheduleLimit);
            concurrentRunTimes = scheduleLimit;
            MaxConcurrentRunTimes = scheduleLimit;
        } else {
            this.scheduleLimit = this.scheduleCfgDic.get(taskType.getSimpleName()).getSchedule_limit();
        }
        // 定期更新任务配置信息

        loadPool.scheduleAtFixedRate(this::loadCfg, cycleScheduleConfigTime, cycleScheduleConfigTime, TimeUnit.MILLISECONDS);
        return 0;
    }




    @Override
    public int destroy() {
        return 0;
    }
    // 枚举
    public enum ObserverType {
        onBoot(0),
        onError(1),
        onExecute(2),
        onFinish(3),
        onStop(4), onObtain(5);
        private int code;

        private ObserverType(int code) {
            this.code = code;
        }

        public int getCode() {
            return code;
        }
    }
}

================
File: worker/src/main/java/com/zdf/worker/boot/Launch.java
================
package com.zdf.worker.boot;

public interface Launch {
    /**
     * Start the server.
     */
    int start();

    /**
     * Destroy the server.
     */
    int destroy();

    int init();

}

================
File: worker/src/main/java/com/zdf/worker/Client/TaskCfgBuilder.java
================
package com.zdf.worker.Client;

import com.zdf.worker.data.ScheduleConfig;

public class TaskCfgBuilder {
    // 构建任务配置
    public ScheduleConfig build(Class<?> clazz, int schedule_limit, int schedule_interval, int max_processing_time, int max_retry_num, int retry_interval) {
        return new ScheduleConfig(clazz.getSimpleName(), schedule_limit, schedule_interval, max_processing_time, max_retry_num, retry_interval, 0L, 0L);
    }
}

================
File: worker/src/main/java/com/zdf/worker/Client/TaskFlower.java
================
package com.zdf.worker.Client;

import com.zdf.worker.data.AsyncTaskRequest;
import com.zdf.worker.data.AsyncTaskReturn;
import com.zdf.worker.data.AsyncTaskSetRequest;
import com.zdf.worker.data.ScheduleConfig;
import com.zdf.worker.enums.TaskStatus;

import java.util.List;

public interface TaskFlower {
    public String createTask(AsyncTaskRequest asyncTaskRequest);
    public void setTask(AsyncTaskSetRequest asyncTaskSetRequest);
    public AsyncTaskReturn getTask(String taskId);
    public List<AsyncTaskReturn> getTaskList(Class<?> clazz, int status, int limit);
    public List<ScheduleConfig> getTaskTypeCfgList();
    public List<AsyncTaskReturn> getUserTaskList(List<TaskStatus> taskStatuses);
    public void createTaskCFG(ScheduleConfig scheduleConfig);


}

================
File: worker/src/main/java/com/zdf/worker/Client/TaskFlowerImpl.java
================
package com.zdf.worker.Client;

import com.alibaba.fastjson.JSON;
import com.zdf.worker.constant.UserConfig;
import com.zdf.worker.data.*;
import com.zdf.worker.enums.ErrorStatus;
import com.zdf.worker.enums.TaskStatus;
import com.zdf.worker.http.FlowServer;
import com.zdf.worker.http.FlowServerImpl;

import java.util.List;

// 对http请求进行封装
public class TaskFlowerImpl implements TaskFlower{
    FlowServer flowServer = new FlowServerImpl();
    @Override
    public String createTask(AsyncTaskRequest asyncTaskRequest) {
        Object o = judgeReturnStatus(flowServer.createTask(asyncTaskRequest));
        String taskId = JSON.parseObject(JSON.toJSONString(o), String.class);
        return taskId;
    }

    @Override
    public void setTask(AsyncTaskSetRequest asyncTaskSetRequest) {
        judgeReturnStatus(flowServer.setTask(asyncTaskSetRequest));
    }

    @Override
    public AsyncTaskReturn getTask(String taskId) {
        Object o = judgeReturnStatus(flowServer.getTask(taskId));
        String s = JSON.toJSONString(o);
        TaskByTaskIdReturn<AsyncTaskReturn> asyncFlowTask = JSON.parseObject(s, TaskByTaskIdReturn.class);
        AsyncTaskReturn asyncTaskReturn = JSON.parseObject(JSON.toJSONString(asyncFlowTask.getTaskData()), AsyncTaskReturn.class);
        return asyncTaskReturn;
    }

    @Override
    public List<AsyncTaskReturn> getTaskList(Class<?> taskType, int status, int limit) {
        Object o = judgeReturnStatus(flowServer.getTaskList(taskType.getSimpleName(), status, limit));
        List<AsyncTaskReturn> asyncTaskReturns = getAsyncTaskReturns(o);
        return asyncTaskReturns;
    }

    @Override
    public List<ScheduleConfig> getTaskTypeCfgList() {
        Object o = judgeReturnStatus(flowServer.getTaskTypeCfgList());
        ConfigReturn configReturn = JSON.parseObject(JSON.toJSONString(o), ConfigReturn.class);
        List<ScheduleConfig> scheduleConfigs = JSON.parseArray(JSON.toJSONString(configReturn.getScheduleCfgList()), ScheduleConfig.class);
        return scheduleConfigs;
    }


    public List<AsyncTaskReturn> doGetUserTaskList(String user_id, int status) {
        Object o = judgeReturnStatus(flowServer.getUserTaskList(user_id, status));
        List<AsyncTaskReturn> asyncTaskReturns = getAsyncTaskReturns(o);
        return asyncTaskReturns;
    }

    @Override
    public List<AsyncTaskReturn> getUserTaskList(List<TaskStatus> taskStatuses) {
        String user_id = UserConfig.USERID;
        int statusList = 0;
        for (TaskStatus status : taskStatuses) {
            statusList |= status.getStatus();
        }
        return doGetUserTaskList(user_id, statusList);
    }

    private List<AsyncTaskReturn> getAsyncTaskReturns(Object o) {
        TaskList taskList = JSON.parseObject(JSON.toJSONString(o), TaskList.class);
        List<AsyncTaskReturn> asyncTaskReturns = JSON.parseArray(JSON.toJSONString(taskList.getTaskList()), AsyncTaskReturn.class);
        return asyncTaskReturns;
    }

    @Override
    public void createTaskCFG(ScheduleConfig scheduleConfig) {
        judgeReturnStatus(flowServer.createTaskCFG(scheduleConfig));
    }

    public <E> E judgeReturnStatus(ReturnStatus<E> returnStatus) {
        if (returnStatus.getCode() != ErrorStatus.SUCCESS.getErrCode()) {
            throw new RuntimeException(returnStatus.getMsg());
        }
        return returnStatus.getResult();
    }
}

================
File: worker/src/main/java/com/zdf/worker/constant/TaskConstant.java
================
package com.zdf.worker.constant;

/**
 * 任务常量
 */
public class TaskConstant {
    public final static int DEFAULT_TIME_INTERVAL = 20;
    public final static int MAX_ERR_MSG_LEN = 256;
    private final static int SCHEDULE_LIMIT = 10;
    private final static int SCHEDULE_INTERVAL = 10;
    private final static int MAX_PROCESSING_TIME = 60;
    private final static int MAX_RETRY_NUM = 5;
    private final static int RETRY_INTERVAL = 10;

}

================
File: worker/src/main/java/com/zdf/worker/constant/TaskUrl.java
================
package com.zdf.worker.constant;

/**
 * 请求URL常量
 */
public class TaskUrl {
    public final static String IPORT = "http://localhost:8081";
    public final static String CREATE_TASK = "/task/create_task";
    public final static String SET_TASK = "/task/set_task";
    public final static String GET_TASK = "/task/get_task";
    public final static String GET_TASK_LIST = "/task/task_list";
    public final static String HOLD_TASK = "/task/hold_task";
    public final static String GET_CFG_LIST = "/task_schedule_cfg/list";
    public final static String GET_USER_TASK_LIST = "/task/user_task_list";
    public final static String CREATE_TASK_CFG = "/task_schedule_cfg/task_configuration";

}

================
File: worker/src/main/java/com/zdf/worker/constant/UserConfig.java
================
package com.zdf.worker.constant;

// 用户配置信息
public class UserConfig {
    public final static String USERID;
    static {
        USERID = "zdf";
    }
    public final static int QUEUE_SIZE = 10000; // 线程池等待队列大小

}

================
File: worker/src/main/java/com/zdf/worker/core/AnnType.java
================
package com.zdf.worker.core;

import com.zdf.worker.boot.AppLaunch;

import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;

@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface AnnType {
    AppLaunch.ObserverType observerType();
    String taskType() default "*";

}

================
File: worker/src/main/java/com/zdf/worker/core/ObserverFunction.java
================
package com.zdf.worker.core;

import com.zdf.worker.data.AsyncTaskBase;
import com.zdf.worker.data.AsyncTaskReturn;
import com.zdf.worker.data.AsyncTaskSetStage;
import com.zdf.worker.data.ScheduleConfig;

import java.util.List;

public interface ObserverFunction {
    void onBoot();
    void onObtain(List<AsyncTaskReturn> taskList, List<AsyncTaskBase> asyncTaskBaseList);
    void onExecute(AsyncTaskBase asyncTaskReturn);
    void onFinish(AsyncTaskBase asyncTaskReturn, AsyncTaskSetStage asyncTaskSetStage, Class<?> aClass);
    void onStop(AsyncTaskBase asyncTaskReturn);
    void onError(AsyncTaskBase asyncTaskReturn, ScheduleConfig scheduleConfig, List<AsyncTaskBase> asyncTaskBaseList, Class<?> aClass, Exception e);

}

================
File: worker/src/main/java/com/zdf/worker/core/ObserverManager.java
================
package com.zdf.worker.core;

import com.zdf.worker.boot.AppLaunch;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.ArrayList;
import java.util.List;

public class ObserverManager {
    List<ObserverFunction> observers;

    public ObserverManager() {
        observers = new ArrayList<>();
    }
    // 添加观察者
    public void registerEventObserver(ObserverFunction observerFunction) {
        observers.add(observerFunction);
    }

    // 通过发射找到对应的方法执行
    public void wakeupObserver(AppLaunch.ObserverType observerType, Object... params) throws InvocationTargetException, IllegalAccessException {
        for (ObserverFunction observer : observers) {
            for (Method method : observer.getClass().getMethods()) {
                if (method.getName().equals(observerType.name())) {
                    method.invoke(observer, params);
                }
            }
        }
    }
}

================
File: worker/src/main/java/com/zdf/worker/core/observers/TimeObserver.java
================
package com.zdf.worker.core.observers;

import com.alibaba.fastjson.JSON;
import com.zdf.worker.Client.TaskFlower;
import com.zdf.worker.Client.TaskFlowerImpl;
import com.zdf.worker.boot.AppLaunch;
import com.zdf.worker.constant.UserConfig;
import com.zdf.worker.core.AnnType;
import com.zdf.worker.core.ObserverFunction;
import com.zdf.worker.data.*;
import com.zdf.worker.enums.TaskStatus;
import com.zdf.worker.task.TaskBuilder;
import com.zdf.worker.task.TaskRet;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.util.List;
import java.util.Objects;
import java.util.UUID;

import static com.zdf.worker.boot.AppLaunch.packageName;

/**
 * 观察者
 */
public class TimeObserver implements ObserverFunction{
    private Long beginTime;
    TaskFlower taskFlower = new TaskFlowerImpl();

    // 获取任务时改变任务状态
    @Override
    @AnnType(observerType = AppLaunch.ObserverType.onObtain)
    public void onObtain(List<AsyncTaskReturn> asyncTaskReturnList, List<AsyncTaskBase> asyncTaskBaseList) {
        System.out.println("开始加载上下文");
        convertModel(asyncTaskReturnList, asyncTaskBaseList);

    }

    public void convertModel(List<AsyncTaskReturn> asyncTaskReturnList, List<AsyncTaskBase> asyncTaskBaseList ) {
        for (AsyncTaskReturn asyncTaskReturn : asyncTaskReturnList) {
            AsyncTaskBase asyncTaskBase = new AsyncTaskBase();
            asyncTaskBase.setUser_id(asyncTaskReturn.getUser_id());
            asyncTaskBase.setTask_id(asyncTaskReturn.getTask_id());
            asyncTaskBase.setTask_type(asyncTaskReturn.getTask_type());
            asyncTaskBase.setTask_stage(asyncTaskReturn.getTask_stage());
            asyncTaskBase.setCrt_retry_num(asyncTaskReturn.getCrt_retry_num());
            asyncTaskBase.setMax_retry_num(asyncTaskReturn.getMax_retry_num());
            asyncTaskBase.setMax_retry_interval(asyncTaskReturn.getMax_retry_interval());
            asyncTaskBase.setCreate_time(asyncTaskReturn.getCreate_time());
            asyncTaskBase.setModify_time(asyncTaskReturn.getModify_time());
            asyncTaskBase.setSchedule_log(JSON.parseObject(String.valueOf(JSON.parse(asyncTaskReturn.getSchedule_log())), ScheduleLog.class));
            TaskRet<NftTaskContext> contextLoad = null;
            try {
                contextLoad = reflictMethod(getaClass(asyncTaskBase.getTask_type()), "contextLoad", new Object[] {asyncTaskReturn.getTask_context()}, new Class[]{String.class});
            } catch (ClassNotFoundException e) {
                e.printStackTrace();
            }
            if (Objects.nonNull(contextLoad)) {
                asyncTaskBase.setTask_context(contextLoad.getResult());
            }
            asyncTaskBase.setTask_context(JSON.parseObject(asyncTaskReturn.getTask_context(), NftTaskContext.class));
            asyncTaskBase.setTask_id(asyncTaskReturn.getTask_id());
            asyncTaskBase.setStatus(asyncTaskReturn.getStatus());
            asyncTaskBaseList.add(asyncTaskBase);
        }
    }

    public Class<?> getaClass(String taskType) throws ClassNotFoundException {
        Class<?> aClass = Class.forName(packageName + "." + taskType);
        return aClass;
    }


    // 执行任务前做的动作，目前是简单打印
    @Override
    @AnnType(observerType = AppLaunch.ObserverType.onExecute)
    public void onExecute(AsyncTaskBase asyncTaskReturn) {
        this.beginTime = System.currentTimeMillis();
        System.out.println(asyncTaskReturn.getTask_type() + "开始执行。");
    }

    // 启动动作
    @Override
    @AnnType(observerType = AppLaunch.ObserverType.onBoot)
    public void onBoot() {
        System.out.println("--------------------------");
        System.out.println("控制台看到这个信息，证明你已经运行成功了~");
        System.out.println(UserConfig.USERID + "的线程" + Thread.currentThread().getName() + "取任务");
    }
    // 执行任务失败时的动作，目前是本地重试
    @Override
    @AnnType(observerType = AppLaunch.ObserverType.onError)
    public void onError(AsyncTaskBase asyncTaskReturn, ScheduleConfig scheduleConfig, List<AsyncTaskBase> asyncTaskBaseList, Class<?> aClass, Exception e) {
//        if (asyncTaskReturn.getCrt_retry_num() < 60) {
//            if (asyncTaskReturn.getCrt_retry_num() != 0) {
//                asyncTaskReturn.setMax_retry_num(asyncTaskReturn.getCrt_retry_num() << 1);
//            }
//        } else {
//            asyncTaskReturn.setMax_retry_interval(scheduleConfig.getRetry_interval());
//        }
//        if (asyncTaskReturn.getMax_retry_interval() > scheduleConfig.getRetry_interval()) {
//            asyncTaskReturn.setMax_retry_interval(scheduleConfig.getRetry_interval());
//        }
//        asyncTaskReturn.getSchedule_log().getLastData().setErrMsg(e.getMessage());
//        if (asyncTaskReturn.getMax_retry_num() == 0 || asyncTaskReturn.getCrt_retry_num() >= asyncTaskReturn.getMax_retry_num()) {
//            AsyncTaskSetRequest asyncTaskSetRequest = modifyStatus(asyncTaskReturn, TaskStatus.FAIL);
//            asyncTaskSetRequest.setCrt_retry_num(asyncTaskReturn.getCrt_retry_num());
//            asyncTaskSetRequest.setMax_retry_interval(asyncTaskReturn.getMax_retry_interval());
//            asyncTaskSetRequest.setMax_retry_num(asyncTaskReturn.getMax_retry_num());
//            setTaskNow(asyncTaskSetRequest);
//            return;
//        }
        System.out.println(asyncTaskReturn.getTask_type() + "任务执行出错！");
        e.printStackTrace();
        AsyncTaskSetRequest asyncTaskSetRequest;
        if (asyncTaskReturn.getMax_retry_num() == 0
                || asyncTaskReturn.getCrt_retry_num() >= asyncTaskReturn.getMax_retry_num()) {
            asyncTaskSetRequest = modifyTaskInfo(asyncTaskReturn, TaskStatus.FAIL, null);
            asyncTaskSetRequest.setSchedule_log(JSON.toJSONString(asyncTaskReturn.getSchedule_log()));
            asyncTaskSetRequest.setCrt_retry_num(asyncTaskReturn.getMax_retry_num());
            reflictMethod(aClass, "handleError", new Object[0], new Class[0]);
        } else {
            asyncTaskSetRequest = modifyTaskInfo(asyncTaskReturn, TaskStatus.PENDING, null);
            asyncTaskSetRequest.setSchedule_log(JSON.toJSONString(asyncTaskReturn.getSchedule_log()));
            asyncTaskSetRequest.setCrt_retry_num(asyncTaskReturn.getCrt_retry_num() + 1);

        }
        asyncTaskSetRequest.setOrder_time(System.currentTimeMillis() + (scheduleConfig.getRetry_interval() << asyncTaskReturn.getCrt_retry_num()));
        asyncTaskSetRequest.setMax_retry_interval(asyncTaskReturn.getMax_retry_interval());
        asyncTaskSetRequest.setMax_retry_num(asyncTaskReturn.getMax_retry_num());
        asyncTaskSetRequest.setSchedule_log(getScheduleLog(asyncTaskReturn, System.currentTimeMillis() - beginTime, e.getMessage()));
        setTaskNow(asyncTaskSetRequest);
    }
    // 任务执行完成做的动作
    @Override
    @AnnType(observerType = AppLaunch.ObserverType.onFinish)
    public void onFinish(AsyncTaskBase asyncTaskReturn, AsyncTaskSetStage asyncTaskSetStage, Class<?> aClass){
        AsyncTaskSetRequest asyncTaskSetRequest = modifyTaskInfo(asyncTaskReturn, TaskStatus.SUCCESS, asyncTaskSetStage);
        long cost = System.currentTimeMillis() - beginTime;
        asyncTaskSetRequest.setSchedule_log(JSON.toJSONString(getScheduleLog(asyncTaskReturn, cost, "")));
        System.out.println(asyncTaskReturn.getTask_type() + "执行完毕！");
        if (Objects.isNull(asyncTaskSetStage)) {
            reflictMethod(aClass, "handleFinish", new Object[0], new Class[0]);
        }
        setTaskNow(asyncTaskSetRequest);
    }

    private TaskRet reflictMethod(Class<?> aClass, String methodName, Object[] params, Class<?>[] paramsType) {
        TaskRet returnVal = null;
        if (Objects.nonNull(aClass)) {
            // 利用Java反射执行本地方法
            Method method = TaskBuilder.getMethod(aClass, methodName, params, paramsType);
            try {
                returnVal = (TaskRet) method.invoke(aClass.newInstance(), params);
                if (returnVal != null) {
                    Object result = returnVal.getResult();
                    System.out.println("执行结果为：" + result);
                }
            } catch (InstantiationException | InvocationTargetException | IllegalAccessException e) {
                e.printStackTrace();
            }
        }
        return returnVal;
    }


    // 获取待定使用
    @Override
    @AnnType(observerType = AppLaunch.ObserverType.onStop)
    public void onStop(AsyncTaskBase asyncTaskReturn){
    }

    // 修改任务状态
    public AsyncTaskSetRequest modifyTaskInfo(AsyncTaskBase asyncTaskBase, TaskStatus taskStatus, AsyncTaskSetStage asyncTaskSetStage) {
        AsyncTaskSetRequest asyncTaskSetRequest = AsyncTaskSetRequest.builder().
                task_id(asyncTaskBase.getTask_id())
                        .task_context(asyncTaskSetStage != null ? JSON.toJSONString(asyncTaskSetStage.getTask_context()) : JSON.toJSONString(asyncTaskBase.getTask_context()))
                                .priority(asyncTaskBase.getPriority())
                                        .task_stage(asyncTaskSetStage != null ? asyncTaskSetStage.getTask_stage() : asyncTaskBase.getTask_stage()).status(taskStatus.getStatus())
                .crt_retry_num(asyncTaskBase.getCrt_retry_num())
                .max_retry_interval(asyncTaskBase.getMax_retry_interval())
                .order_time(asyncTaskSetStage != null ? System.currentTimeMillis() - asyncTaskBase.getPriority() : asyncTaskBase.getOrder_time() - asyncTaskBase.getPriority())
                .build();
        asyncTaskSetRequest.setStatus(asyncTaskSetStage != null ? TaskStatus.PENDING.getStatus() : taskStatus.getStatus());
        return asyncTaskSetRequest;
    }

    public String getScheduleLog(AsyncTaskBase asyncTaskReturn, long costTime, String errMsg) {
        // 记录调度信息
        ScheduleLog scheduleLog = asyncTaskReturn.getSchedule_log();
        ScheduleData lastData = scheduleLog.getLastData();
        List<ScheduleData> historyDatas = scheduleLog.getHistoryDatas();
        historyDatas.add(lastData);
        if (historyDatas.size() > 3) {
            historyDatas.remove(0);
        }
        ScheduleData scheduleData = new ScheduleData(UUID.randomUUID() + "", errMsg, costTime + "");
        scheduleLog.setLastData(scheduleData);
        return JSON.toJSONString(scheduleLog);
    }

    // 修改任务信息
    public void setTaskNow(AsyncTaskSetRequest asyncTaskSetRequest) {
        taskFlower.setTask(asyncTaskSetRequest);
    }
}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncFlowClientData.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class AsyncFlowClientData {

    private String user_id;

    private String task_type;
    
    private String task_stage;

    private String schedule_log;

    private String task_context;




}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncFlowTask.java
================
package com.zdf.worker.data;

import lombok.Data;

@Data
public class AsyncFlowTask {
    
    private Long id;
    
    private String user_id; //NOT NULL DEFAULT '',
    
    private String task_id; // NOT NULL DEFAULT '',
    
    private String task_type; //NOT NULL DEFAULT '',  存储任务的全类名
    
    private String task_stage; //NOT NULL DEFAULT '', 存储任务阶段信息
    
    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',

    private long order_time;

    private int priority;
    
    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',
    
    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',
    
    private int max_retry_interval;// int(11) NOT NULL DEFAULT '0' COMMENT '最大重试间隔',
    
    private String schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',
    
    private String task_context;// varchar(8192) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '任务上下文，用户自定义',
    
    private Long create_time;// datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    private Long modify_time;// datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,


}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncTaskBase.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class AsyncTaskBase {
    private String user_id; //NOT NULL DEFAULT '',

    private String task_id; // NOT NULL DEFAULT '',

    private String task_type; //NOT NULL DEFAULT '',  存储任务的全类名

    private String task_stage; //NOT NULL DEFAULT '', 存储任务阶段信息

    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',

    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',

    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',

    private long order_time;

    private int priority;

    private int max_retry_interval;// int(11) NOT NULL DEFAULT '0' COMMENT '最大重试间隔',

    private ScheduleLog schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',

    private NftTaskContext task_context;// varchar(8192) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '任务上下文，用户自定义',

    private Long create_time;// datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,

    private Long modify_time;
}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncTaskRequest.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class AsyncTaskRequest {
    AsyncFlowClientData taskData;
}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncTaskReturn.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class AsyncTaskReturn {
    private String user_id; //NOT NULL DEFAULT '',

    private String task_id; // NOT NULL DEFAULT '',

    private String task_type; //NOT NULL DEFAULT '',

    private String task_stage; //NOT NULL DEFAULT '',

    private long order_time;

    private int priority;

    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',

    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',

    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',

    private int max_retry_interval;// int(11) NOT NULL DEFAULT '0' COMMENT '最大重试间隔',

    private String schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',

    private String task_context;

    private Long create_time;

    private Long modify_time;

}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncTaskSetRequest.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
public class AsyncTaskSetRequest {
    private String task_id; // NOT NULL DEFAULT '',
    private String task_stage;
    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',
    private String schedule_log;// varchar(4096) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '调度信息记录',
    private String task_context;
    private long order_time;
    private int priority;
    private int crt_retry_num; //NOT NULL DEFAULT '0' COMMENT '已经重试几次了',
    private int max_retry_num; //NOT NULL DEFAULT '0' COMMENT '最大能重试几次',
    private int max_retry_interval;



}

================
File: worker/src/main/java/com/zdf/worker/data/AsyncTaskSetStage.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;

@Data
@AllArgsConstructor
@Builder
public class AsyncTaskSetStage {

    private String task_stage; //NOT NULL DEFAULT '', 存储任务阶段信息

    private int status; //tinyint(3) unsigned NOT NULL DEFAULT '0',

    private NftTaskContext task_context;// varchar(8192) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT '' COMMENT '任务上下文，用户自定义',

}

================
File: worker/src/main/java/com/zdf/worker/data/ConfigReturn.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.List;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class ConfigReturn {
    List<ScheduleConfig> scheduleCfgList;
}

================
File: worker/src/main/java/com/zdf/worker/data/NftTaskContext.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class NftTaskContext {
    private Object[] params;
    private Object[] envs;
    private Class<?>[] clazz;
}

================
File: worker/src/main/java/com/zdf/worker/data/ReturnStatus.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class ReturnStatus<E> {
    private String msg;
    private int code;
    private E result;
}

================
File: worker/src/main/java/com/zdf/worker/data/ScheduleConfig.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class ScheduleConfig {
    private String task_type;
    private Integer schedule_limit;
    private Integer schedule_interval;
    private Integer max_processing_time;
    private Integer max_retry_num;
    private Integer retry_interval;
    private Long create_time;
    private Long modify_time;
}

================
File: worker/src/main/java/com/zdf/worker/data/ScheduleData.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
@Builder
public class ScheduleData {
    String traceId;
    String errMsg;
    String cost;
}

================
File: worker/src/main/java/com/zdf/worker/data/ScheduleLog.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;

import java.util.ArrayList;
import java.util.List;

@Data
@AllArgsConstructor
@Builder
public class ScheduleLog {
    ScheduleData lastData;
    List<ScheduleData> historyDatas;
    public ScheduleLog() {
        lastData = new ScheduleData();
        historyDatas = new ArrayList<>();
    }
}

================
File: worker/src/main/java/com/zdf/worker/data/TaskByTaskIdReturn.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class TaskByTaskIdReturn<E> {
    E taskData;
}

================
File: worker/src/main/java/com/zdf/worker/data/TaskList.java
================
package com.zdf.worker.data;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.List;

@Data
@AllArgsConstructor
@NoArgsConstructor
public class TaskList {
    List<AsyncTaskReturn> taskList;
}

================
File: worker/src/main/java/com/zdf/worker/enums/ErrorStatus.java
================
package com.zdf.worker.enums;

// 错误状态
public enum ErrorStatus {
    SUCCESS(0, "ok"),
    ERR_INPUT_INVALID(8020, "input invalid"),
    ERR_SHOULD_BIND(8021, "should bind failed"),
    ERR_JSON_MARSHAL(8022, "json marshal failed"),
    ERR_GET_TASK_INFO(8035, "get task info failed"),
    ERR_GET_TASK_HANDLE_PROCESS(8036, "get task handle process Failed"),
    ERR_CREATE_TASK(8037, "create task failed"),
    ERR_GET_TASK_LIST_FROM_DB(8038, "get task list from db failed"),
    ERR_GET_TASK_SET_POS_FROM_DB(8039, "get task set pos from db failed"),
    ERR_INCREASE_CRT_RETRY_NUM(8040, "set task failed"),
    ERR_SET_TASK(8041, "increase crt retry num failed"),
    ERR_GET_TASK_POS(8042, "get task pos failed"),
    ERR_GET_PROCESSING_COUNT(8043, "get processing count failed"),
    ERR_SET_USER_PRIORITY(8045, "set user priority failed"),
    ERR_GET_TASK_CFG_FROM_DB(8039, "get task cfg failed");

    private int errCode;
    private String msg;
    private ErrorStatus(int errCode, String msg) {
        this.errCode = errCode;
        this.msg = msg;
    }

    public int getErrCode() {
        return errCode;
    }

    public String getMsg() {
        return msg;
    }
}

================
File: worker/src/main/java/com/zdf/worker/enums/TaskStatus.java
================
package com.zdf.worker.enums;

import java.util.ArrayList;
import java.util.List;

// 任务状态
public enum TaskStatus {
    // 待执行
    PENDING(0x01),
    // 执行中
    EXECUTING(0x02),
    // 执行成功
    SUCCESS(0x04),
    // 执行失败
    FAIL(0x08);

    private TaskStatus(int status) {
        this.status = status;
    }
    private int status;

    public int getStatus() {
        return this.status;
    }

    public List<TaskStatus> getAliveStatus() {
        List<TaskStatus> aliveList = new ArrayList<>();
        aliveList.add(PENDING);
        aliveList.add(EXECUTING);
        return aliveList;
    }
    public List<TaskStatus> getFailStatus() {
        List<TaskStatus> failList = new ArrayList<>();
        failList.add(FAIL);
        return failList;
    }

    public List<TaskStatus> getSuccessStatus() {
        List<TaskStatus> sucList = new ArrayList<>();
        sucList.add(SUCCESS);
        return sucList;
    }

    public List<TaskStatus> getAllStatus() {
        List<TaskStatus> list = new ArrayList<>();
        for (TaskStatus value : TaskStatus.values()) {
            list.add(value);
        }
        return list;
    }
}

================
File: worker/src/main/java/com/zdf/worker/http/FlowServer.java
================
package com.zdf.worker.http;

import com.zdf.worker.data.*;


public interface FlowServer {
    ReturnStatus getTaskList(String taskType, int status, int limit);
    ReturnStatus createTask(AsyncTaskRequest asyncTaskRequest);
    ReturnStatus setTask(AsyncTaskSetRequest asyncTaskSetRequest);
    ReturnStatus getTask(String taskId);

    ReturnStatus getTaskTypeCfgList();
    ReturnStatus getUserTaskList(String user_id, int statusList);
    ReturnStatus createTaskCFG(ScheduleConfig scheduleConfig);

}

================
File: worker/src/main/java/com/zdf/worker/http/FlowServerImpl.java
================
package com.zdf.worker.http;

import com.alibaba.fastjson.JSON;
import com.zdf.worker.constant.TaskUrl;
import com.zdf.worker.data.AsyncTaskRequest;
import com.zdf.worker.data.AsyncTaskSetRequest;
import com.zdf.worker.data.ReturnStatus;
import com.zdf.worker.data.ScheduleConfig;
import okhttp3.*;

import java.io.IOException;
import java.util.HashMap;
import java.util.Map;

// 利用OKhttp发起端口请求
public class FlowServerImpl implements FlowServer {
    OkHttpClient client = new OkHttpClient();

    // get方法
    public ReturnStatus get(String url) {

        Request request = new Request.Builder().url(url)
                .get()
                .build();
        try (Response response = client.newCall(request).execute()) {
            String result = response.body().string();
            return JSON.parseObject(result, ReturnStatus.class);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return null;
    }

    // 拼接url参数
    private String getParamStr(Map<String, String> params) {
        StringBuffer sb = new StringBuffer();
        sb.append("?");
        for (Map.Entry<String, String> entry : params.entrySet()) {
            sb.append(entry.getKey()).append("=").append(entry.getValue()).append("&");
        }
        return sb.deleteCharAt(sb.length() - 1).toString();
    }

    // post请求
    public <E> ReturnStatus post(String url, E body) {
        Request request = new Request.Builder()
                .addHeader("content-type", "application/json")
                .url(TaskUrl.IPORT + url)
                .post(RequestBody.create(MediaType.parse("application/json; charset=utf-8"), JSON.toJSONString(body)))
                .build();

        String result;
        try {
            result = client.newCall(request).execute().body().string();
            return JSON.parseObject(result, ReturnStatus.class);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return null;

    }

    // 获取任务列表url
    @Override
    public ReturnStatus getTaskList(String taskType, int status, int limit) {
        Map<String, String> params = new HashMap<String, String>() {{
            put("task_type", taskType);
            put("status", status + "");
            put("limit", limit + "");
        }};
        String url = TaskUrl.IPORT + TaskUrl.HOLD_TASK + getParamStr(params);
        return get(url);
    }

    // 调用创建任务接口
    @Override
    public ReturnStatus createTask(AsyncTaskRequest asyncTaskRequest) {
        return post(TaskUrl.CREATE_TASK, asyncTaskRequest);
    }

    // 调用更改任务信息接口
    @Override
    public ReturnStatus setTask(AsyncTaskSetRequest asyncTaskSetRequest) {
        return post(TaskUrl.SET_TASK, asyncTaskSetRequest);
    }

    // 通过task_id获取任务
    @Override
    public ReturnStatus getTask(String taskId) {
        Map<String, String> params = new HashMap<>();
        params.put("task_id", taskId);
        String url = TaskUrl.IPORT + TaskUrl.GET_TASK + getParamStr(params);
        return get(url);
    }

    // 获取任务配置信息
    @Override
    public ReturnStatus getTaskTypeCfgList() {
       return get(TaskUrl.IPORT + TaskUrl.GET_CFG_LIST);
    }

    // 根据任务状态获取用户对应的任务列表
    @Override
    public ReturnStatus getUserTaskList(String user_id, int statusList) {
        Map<String, String> params = new HashMap<>();
        params.put("user_id", user_id);
        params.put("statusList", statusList + "");
        return get(TaskUrl.IPORT + TaskUrl.GET_USER_TASK_LIST + getParamStr(params));
    }

    // 创建任务配置信息接口
    @Override
    public ReturnStatus createTaskCFG(ScheduleConfig scheduleConfig) {
        return post(TaskUrl.IPORT + TaskUrl.CREATE_TASK_CFG, scheduleConfig);
    }


}

================
File: worker/src/main/java/com/zdf/worker/lock/LockParam.java
================
package com.zdf.worker.lock;

import lombok.Data;

@Data
public class LockParam {
    private static Long HOLD_LOCK_TIME = 5L;
    private static Long TRY_LOCK_TIME = 10L;

    private String lockKey;
    private String lockValue;
    private Long holdLockTime;
    // 最大尝试时间，防止无限期抢锁
    private Long tryLockTime;


    public LockParam(String lockKey) {
        this(lockKey, 5 * 1000L, 5L);
    }

    public LockParam(String lockKey, Long tryLockTime) {
        this(lockKey, tryLockTime, 3000L);
    }

    public LockParam(String lockKey, Long tryLockTime, Long holdLockTime) {
        this.lockKey = lockKey;
        this.tryLockTime = tryLockTime;
        this.holdLockTime = holdLockTime;
    }
}

================
File: worker/src/main/java/com/zdf/worker/lock/RedisLock.java
================
package com.zdf.worker.lock;

import redis.clients.jedis.Jedis;

import java.util.Collections;
import java.util.UUID;

public class RedisLock {
    private Long tryLockEndTime;
    private String lockValue;
    private LockParam lockParam;
    private final String LOCK_SUCCESS = "OK";
    private final Long UNLOCK_SUCCESS = 1L;
    private final String passwd = "password";
    // KEY[1] = lockKey
    // ARGC[1] = lockValue
    private final static  String unLockScript = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";

    private Jedis jedis;

    public RedisLock(LockParam lockParam) {
        if (lockParam == null) {
            throw new RuntimeException("LockParam is null.");
        }
        this.lockParam = lockParam;
        this.lockValue = UUID.randomUUID().toString();
        this.tryLockEndTime = System.currentTimeMillis() + lockParam.getTryLockTime();
        this.jedis = new Jedis("localhost", 6379);
        this.jedis.auth(passwd);
    }

    public void close() {
        this.jedis.close();
    }

    public boolean lock() {
        while (true) {
            if (System.currentTimeMillis() > tryLockEndTime) {
                return false;
            }
            if (tryLock()) {
                return true;
            } else {
                // 加锁失败后重试
                try {
                    Thread.sleep(50L);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    // 加锁
    public boolean tryLock() {
        String flag;
        flag = jedis.set(this.lockParam.getLockKey(), this.lockValue, "NX", "EX", this.lockParam.getHoldLockTime());
        if (LOCK_SUCCESS.equals(flag)) {
            return true;
        }
        return false;
    }
    public boolean unlock() {
        Object eval ;
        try {
            // 执行lua脚本释放锁
            eval = jedis.eval(unLockScript, Collections.singletonList(this.lockParam.getLockKey()), Collections.singletonList(this.lockValue));
            if (UNLOCK_SUCCESS.equals(eval)) {
                return true;
            }
        } finally {
            this.close();
        }
        return false;
    }
}

================
File: worker/src/main/java/com/zdf/worker/task/AsyncExecutable.java
================
package com.zdf.worker.task;

import com.zdf.worker.data.AsyncTaskSetStage;
import com.zdf.worker.data.NftTaskContext;
import com.zdf.worker.enums.TaskStatus;

import java.lang.reflect.Method;

public interface AsyncExecutable<T> {
    TaskRet<T> handleProcess();
    TaskRet<T> handleFinish();
    TaskRet<T> handleError();
    TaskRet<T> contextLoad(String context);

    default AsyncTaskSetStage setStage(Class<?> clazz, String methodName, Object[] params, Class<?>[] parameterTypes, Object... envs) {
        return build(clazz, methodName, params, parameterTypes, envs);
    }


    // 利用类信息创建任务
    default AsyncTaskSetStage build(Class<?> clazz, String methodName, Object[] params, Class<?>[] parameterTypes, Object... envs) {
        TaskBuilder.checkParamsNum(params, parameterTypes);
        Method method = TaskBuilder.getMethod(clazz, methodName, params, parameterTypes);

        // get 方法名
        String taskStage = method.getName();

        // 上下文信息
        NftTaskContext nftTaskContext = new NftTaskContext(params, envs, parameterTypes);
        return AsyncTaskSetStage.builder()
                .status(TaskStatus.PENDING.getStatus())
                .task_context(nftTaskContext)
                .task_stage(taskStage)
                .build();
    }

    default boolean judgeParamsTypes(Method clazzMethod, Class<?>[] parameterTypes) {
        Class<?>[] types = clazzMethod.getParameterTypes();
        for (int i = 0; i < types.length; i++) {
            if (types[i] != parameterTypes[i]) {
                return false;
            }
        }
        return true;
    }
}

================
File: worker/src/main/java/com/zdf/worker/task/Lark.java
================
package com.zdf.worker.task;

import com.alibaba.fastjson.JSON;
import com.zdf.worker.data.AsyncTaskSetStage;
import com.zdf.worker.data.NftTaskContext;

import java.lang.reflect.Method;

// 测试任务
// 此处可以定义自己的任务
public class Lark implements AsyncExecutable {
    public TaskRet printMsg(String msg) {
        System.out.println("The printed msg is: " + msg);
        AsyncTaskSetStage asyncTaskSetStage = null;
        try {
            Method method = this.getClass().getMethod("printMsg2", String.class);
            asyncTaskSetStage = setStage(this.getClass(), method.getName(), new Object[]{"我要开花！"}, method.getParameterTypes());
        } catch (NoSuchMethodException e) {
            e.printStackTrace();
        }
        return new TaskRet("SUCCESS", asyncTaskSetStage);
    }

    public TaskRet printMsg2(String msg) {
        System.out.println("第二阶段开启中文打印: " + msg);
        return new TaskRet("执行成功");
    }

    @Override
    public TaskRet handleProcess() {
        return printMsg("I did it!");
    }

    @Override
    public TaskRet handleFinish() {
        System.out.println("任务后置处理，可以自定义做点任务执行成功后的后置处理，例如回收资源等");
        return new TaskRet("全部任务阶段执行完毕~");
    }

    @Override
    public TaskRet handleError() {
        System.out.println("任务最终执行失败干点事，可以自定义一些操作");
        return new TaskRet("任务实在是执行不了了，还是人工检查一下吧~");
    }

    @Override
    public TaskRet contextLoad(String context) {
        System.out.println("上下文加载，用户可以根据自己定义的协议格式对上下文进行解析");
        NftTaskContext nftTaskContext = JSON.parseObject(context, NftTaskContext.class);
        return new TaskRet<>(nftTaskContext);
    }
}

================
File: worker/src/main/java/com/zdf/worker/task/TaskBuilder.java
================
package com.zdf.worker.task;

import com.alibaba.fastjson.JSON;
import com.zdf.worker.constant.UserConfig;
import com.zdf.worker.data.AsyncFlowClientData;
import com.zdf.worker.data.NftTaskContext;
import com.zdf.worker.data.ScheduleLog;

import java.lang.reflect.Method;

/**
 * @author zhangdafeng
 */
public class TaskBuilder {

    public static AsyncFlowClientData build(AsyncExecutable executable) throws NoSuchMethodException {
        Class<? extends AsyncExecutable> aClass = executable.getClass();
        Method handProcess = aClass.getMethod("handleProcess");
        return TaskBuilder.build(aClass, handProcess.getName(), new Object[0], new Class[0]);
    }

    // 利用类信息创建任务
    public static AsyncFlowClientData build(Class<?> clazz, String methodName, Object[] params, Class<?>[] parameterTypes, Object... envs) {
        if (!AsyncExecutable.class.isAssignableFrom(clazz)) {
            throw new RuntimeException("The task must be implemented TaskDefinition!");
        }
        checkParamsNum(params, parameterTypes);
        Method method = getMethod(clazz, methodName, params, parameterTypes);

        // 获取类名
        String taskType = method.getDeclaringClass().getSimpleName();
        // get 方法名
        String taskStage = method.getName();
        // 调度日志
        ScheduleLog sl = new ScheduleLog();
        String scheduleLog = JSON.toJSONString(sl);

        // 上下文信息
        NftTaskContext nftTaskContext = new NftTaskContext(params, envs, parameterTypes);
        String taskContext = JSON.toJSONString(nftTaskContext);
        return new AsyncFlowClientData(
                UserConfig.USERID,
                taskType,
                taskStage,
                scheduleLog,
                taskContext
        );
    }

    public static void checkParamsNum(Object[] params, Class<?>[] parameterTypes) {
        // 参数个数检验
        if (params.length != parameterTypes.length) {
            throw new RuntimeException("Parameters are invalid!");
        }
    }

    public static Method getMethod(Class<?> clazz, String methodName, Object[] params, Class<?>[] parameterTypes) {
        Method method = null;
        for (Method clazzMethod : clazz.getMethods()) {
            // 获取对应要执行的方法
            if (clazzMethod.getName().equals(methodName) && clazzMethod.getParameterCount() == params.length && judgeParamsTypes(clazzMethod, parameterTypes)) {
                method = clazzMethod;
            }
        }

        return method;
    }


    private static boolean judgeParamsTypes(Method clazzMethod, Class<?>[] parameterTypes) {
        Class<?>[] types = clazzMethod.getParameterTypes();
        for (int i = 0; i < types.length; i++) {
            if (types[i] != parameterTypes[i]) {
                return false;
            }
        }
        return true;
    }
}

================
File: worker/src/main/java/com/zdf/worker/task/TaskRet.java
================
package com.zdf.worker.task;

import com.zdf.worker.data.AsyncTaskSetStage;
import lombok.Data;

@Data
public class TaskRet<T> {
    T result;
    AsyncTaskSetStage asyncTaskSetStage;
    public TaskRet(T result) {
        this(result, null);
    }
    public TaskRet(T result, AsyncTaskSetStage asyncTaskSetStage) {
        this.result = result;
        this.asyncTaskSetStage = asyncTaskSetStage;
    }

}

================
File: worker/src/main/java/com/zdf/worker/test/Test.java
================
package com.zdf.worker.test;

import com.zdf.worker.Client.TaskFlower;
import com.zdf.worker.Client.TaskFlowerImpl;
import com.zdf.worker.data.AsyncFlowClientData;
import com.zdf.worker.data.AsyncTaskRequest;
import com.zdf.worker.data.AsyncTaskReturn;
import com.zdf.worker.task.Lark;
import com.zdf.worker.task.TaskBuilder;

import java.util.List;

public class Test {
    static TaskFlower taskFlower = new TaskFlowerImpl();
    public static void main(String[] args) {
        // 用于测试创建任务
        testCeateTask();
//        testSetTask();

    }

    private static void testGetTaskList() {
        List<AsyncTaskReturn> larkTask = taskFlower.getTaskList(Lark.class, 1, 5);
        System.out.println(larkTask);
    }

    private static void testSetTask() {
//        AsyncTaskSetRequest asyncTaskSetRequest = AsyncTaskSetRequest.builder()

//        asyncTaskSetRequest.setStatus(TaskStatus.PENDING.getStatus());
//        taskFlower.setTask(asyncTaskSetRequest);
    }

    private static void testGetTask() {
        AsyncTaskReturn task = taskFlower.getTask("123");
        System.out.println(task);
    }

    private static void testCeateTask() {
        AsyncFlowClientData asyncFlowClientData = null;
        try {
            asyncFlowClientData = TaskBuilder.build(new Lark());
        } catch (NoSuchMethodException e) {
            e.printStackTrace();
        }
        String task = taskFlower.createTask(new AsyncTaskRequest(asyncFlowClientData));
    }

    private static void createTaskConfig() {

    }
}

================
File: worker/src/main/java/com/zdf/worker/WorkerApplication.java
================
package com.zdf.worker;

import com.zdf.worker.boot.AppLaunch;
import com.zdf.worker.boot.Launch;
import com.zdf.worker.task.Lark;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class WorkerApplication implements CommandLineRunner {

    public static void main(String[] args) {
        SpringApplication.run(WorkerApplication.class, args);
    }

    @Override
    public void run(String... args) throws Exception {
        Launch l = new AppLaunch();
        // 启动worker
        l.start();
    }
}

================
File: worker/src/main/resources/application.properties
================


================
File: worker/src/test/java/com/zdf/worker/WorkerApplicationTests.java
================
package com.zdf.worker;

import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;

@SpringBootTest
class WorkerApplicationTests {

    @Test
    void contextLoads() {
    }

}



================================================================
End of Codebase
================================================================
